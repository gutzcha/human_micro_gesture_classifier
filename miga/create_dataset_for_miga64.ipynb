{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-13T01:19:21.768499400Z",
     "start_time": "2024-05-13T01:19:21.749463700Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import os.path as osp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from glob import glob\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "path_to_csv_files = r'C:\\Users\\gutzc\\GitHub\\human_micro_gesture_classifier\\miga_dataset\\SMG_RGB_Phase1\\split_files_csv'\n",
    "\n",
    "all_csv_files = glob(osp.join(path_to_csv_files, '*.csv'))\n",
    "print(len(all_csv_files))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T01:13:23.648178900Z",
     "start_time": "2024-05-13T01:13:23.637769800Z"
    }
   },
   "id": "a1deffe79db0ab10"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3451\n",
      "Index(['Unnamed: 0', 'file_name', 'start_frame', 'end_frame', 'labels',\n",
      "       'multihot_labels', 'frame_numbers', 'source_folder', 'source_video'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": "   Unnamed: 0                    file_name  start_frame  end_frame labels  \\\n0           0  0001_000_00164-00228_14.mp4          100        164   [14]   \n1           1  0001_001_00831-00895_14.mp4          164        228   [14]   \n2           2  0001_002_01697-01761_11.mp4          831        895   [11]   \n3           3  0001_003_04835-04899_11.mp4         1697       1761   [11]   \n4           4   0001_004_06317-06381_7.mp4         4835       4899    [7]   \n\n                                     multihot_labels  \\\n0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n\n                                       frame_numbers  \\\n0  [100, 101, 102, 103, 104, 105, 106, 107, 108, ...   \n1  [164, 165, 166, 167, 168, 169, 170, 171, 172, ...   \n2  [831, 832, 833, 834, 835, 836, 837, 838, 839, ...   \n3  [1697, 1698, 1699, 1700, 1701, 1702, 1703, 170...   \n4  [4835, 4836, 4837, 4838, 4839, 4840, 4841, 484...   \n\n                                       source_folder          source_video  \n0  C:\\Users\\gutzc\\GitHub\\human_micro_gesture_clas...  Sample0001_color.mp4  \n1  C:\\Users\\gutzc\\GitHub\\human_micro_gesture_clas...  Sample0001_color.mp4  \n2  C:\\Users\\gutzc\\GitHub\\human_micro_gesture_clas...  Sample0001_color.mp4  \n3  C:\\Users\\gutzc\\GitHub\\human_micro_gesture_clas...  Sample0001_color.mp4  \n4  C:\\Users\\gutzc\\GitHub\\human_micro_gesture_clas...  Sample0001_color.mp4  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>file_name</th>\n      <th>start_frame</th>\n      <th>end_frame</th>\n      <th>labels</th>\n      <th>multihot_labels</th>\n      <th>frame_numbers</th>\n      <th>source_folder</th>\n      <th>source_video</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0001_000_00164-00228_14.mp4</td>\n      <td>100</td>\n      <td>164</td>\n      <td>[14]</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[100, 101, 102, 103, 104, 105, 106, 107, 108, ...</td>\n      <td>C:\\Users\\gutzc\\GitHub\\human_micro_gesture_clas...</td>\n      <td>Sample0001_color.mp4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>0001_001_00831-00895_14.mp4</td>\n      <td>164</td>\n      <td>228</td>\n      <td>[14]</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[164, 165, 166, 167, 168, 169, 170, 171, 172, ...</td>\n      <td>C:\\Users\\gutzc\\GitHub\\human_micro_gesture_clas...</td>\n      <td>Sample0001_color.mp4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>0001_002_01697-01761_11.mp4</td>\n      <td>831</td>\n      <td>895</td>\n      <td>[11]</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[831, 832, 833, 834, 835, 836, 837, 838, 839, ...</td>\n      <td>C:\\Users\\gutzc\\GitHub\\human_micro_gesture_clas...</td>\n      <td>Sample0001_color.mp4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>0001_003_04835-04899_11.mp4</td>\n      <td>1697</td>\n      <td>1761</td>\n      <td>[11]</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>[1697, 1698, 1699, 1700, 1701, 1702, 1703, 170...</td>\n      <td>C:\\Users\\gutzc\\GitHub\\human_micro_gesture_clas...</td>\n      <td>Sample0001_color.mp4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0001_004_06317-06381_7.mp4</td>\n      <td>4835</td>\n      <td>4899</td>\n      <td>[7]</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n      <td>[4835, 4836, 4837, 4838, 4839, 4840, 4841, 484...</td>\n      <td>C:\\Users\\gutzc\\GitHub\\human_micro_gesture_clas...</td>\n      <td>Sample0001_color.mp4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_list = [pd.read_csv(p) for p in all_csv_files]\n",
    "df = pd.concat(df_list)\n",
    "# correct columns\n",
    "df['labels'] = df['labels'].apply(lambda x: ast.literal_eval(x))\n",
    "df['multihot_labels'] = df['multihot_labels'].apply(lambda x: np.array(ast.literal_eval(x.replace(' ',','))))\n",
    "print(len(df))\n",
    "print(df.columns)\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T01:33:13.819381800Z",
     "start_time": "2024-05-13T01:33:13.597686700Z"
    }
   },
   "id": "5f1f56354537869c"
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# see labels distribution\n",
    "all_labels = df.labels.values.tolist()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T01:33:15.064152500Z",
     "start_time": "2024-05-13T01:33:15.055145100Z"
    }
   },
   "id": "a3f4907fbda12f6e"
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([  57.,   83.,  292.,   17., 1112.,   48.,  165.,  464., 1199.,\n          21.,   19.,  294.,   79.,  104.,   18.,   40.,   73.]),\n array([ 0.        ,  0.94117647,  1.88235294,  2.82352941,  3.76470588,\n         4.70588235,  5.64705882,  6.58823529,  7.52941176,  8.47058824,\n         9.41176471, 10.35294118, 11.29411765, 12.23529412, 13.17647059,\n        14.11764706, 15.05882353, 16.        ]),\n <BarContainer object of 17 artists>)"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labels_flat = [a for sub in all_labels for a in sub]\n",
    "plt.hist(labels_flat, bins=17)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T01:33:16.273473600Z",
     "start_time": "2024-05-13T01:33:16.115362900Z"
    }
   },
   "id": "e291482e8a010d57"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "from skmultilearn.model_selection import iterative_train_test_split\n",
    "X = df['file_name'].values\n",
    "X = X.reshape(-1,1)\n",
    "\n",
    "y = df['multihot_labels'].values\n",
    "y = np.stack(y)\n",
    "\n",
    "X_train, y_train, X_test, y_test = iterative_train_test_split(X, y, test_size = 0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T01:35:11.006759100Z",
     "start_time": "2024-05-13T01:35:10.951604300Z"
    }
   },
   "id": "2bdb0df3b32d95d7"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# check out resutls\n",
    "df_ind = df.set_index('file_name', drop=True)\n",
    "df_train_raw = df_ind.loc[X_train.squeeze()]\n",
    "df_val_raw = df_ind.loc[X_test.squeeze()]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T01:49:57.114357200Z",
     "start_time": "2024-05-13T01:49:57.099787600Z"
    }
   },
   "id": "c7599a816c76976"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'file_name', 'start_frame', 'end_frame', 'labels',\n",
      "       'multihot_labels', 'frame_numbers', 'source_folder', 'source_video'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T01:49:58.793213900Z",
     "start_time": "2024-05-13T01:49:58.786685700Z"
    }
   },
   "id": "6ac46647e59593ea"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "# columns i need:\n",
    "def convert_df(df_in):\n",
    "        \n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    df_out['filenames'] = df_in['file_name']\n",
    "    df_out['folder_name'] = ''\n",
    "    df_out['durations'] = 64\n",
    "    \n",
    "    df_out['view'] = 'center'\n",
    "    metadata = pd.DataFrame()\n",
    "        \n",
    "    metadata['sample_id'] = df_out['filenames'].apply(lambda x: x.split('.')[0])\n",
    "    metadata['start_frame'] = df_in['start_frame']\n",
    "    metadata['end_frame'] = df_in['end_frame']\n",
    "    metadata['label']= df_in['labels']\n",
    "    metadata['view'] =  df_out['view']\n",
    "    metadata['filenames'] = df_out['filenames']\n",
    "    metadata['durations'] = df_out['durations']\n",
    "    # cat = df_in['label']\n",
    "    # categories = list(LABEL2ID.keys())\n",
    "    # one_hot_encoded = pd.get_dummies(cat.astype(pd.CategoricalDtype(categories=categories)))\n",
    "    \n",
    "    # new_columns = one_hot_encoded.columns.to_list()\n",
    "    # one_hot_encoded = one_hot_encoded.astype(float)\n",
    "    df_out['labels'] = df_in['multihot_labels']\n",
    "    # df_out['labels'] = df_in['label'] - 1\n",
    "    df_out['metadata'] = metadata.to_dict(orient='records')\n",
    "    \n",
    "    return df_out"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T01:50:02.958919400Z",
     "start_time": "2024-05-13T01:50:02.953855Z"
    }
   },
   "id": "439291df4014673"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "df_val = convert_df(df_in=df_val_raw.reset_index())\n",
    "df_train = convert_df(df_in=df_train_raw.reset_index())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T01:50:43.857303400Z",
     "start_time": "2024-05-13T01:50:43.835522500Z"
    }
   },
   "id": "a417f82de63b90f5"
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [
    {
     "data": {
      "text/plain": "                     filenames folder_name  durations    view  \\\n0  0001_000_00164-00228_14.mp4                     64  center   \n1  0001_003_04835-04899_11.mp4                     64  center   \n2   0001_005_06437-06501_8.mp4                     64  center   \n3   0001_007_06547-06611_8.mp4                     64  center   \n4   0001_009_06620-06684_8.mp4                     64  center   \n\n                                              labels  \\\n0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n\n                                            metadata  \n0  {'sample_id': '0001_000_00164-00228_14', 'star...  \n1  {'sample_id': '0001_003_04835-04899_11', 'star...  \n2  {'sample_id': '0001_005_06437-06501_8', 'start...  \n3  {'sample_id': '0001_007_06547-06611_8', 'start...  \n4  {'sample_id': '0001_009_06620-06684_8', 'start...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filenames</th>\n      <th>folder_name</th>\n      <th>durations</th>\n      <th>view</th>\n      <th>labels</th>\n      <th>metadata</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0001_000_00164-00228_14.mp4</td>\n      <td></td>\n      <td>64</td>\n      <td>center</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>{'sample_id': '0001_000_00164-00228_14', 'star...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0001_003_04835-04899_11.mp4</td>\n      <td></td>\n      <td>64</td>\n      <td>center</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>{'sample_id': '0001_003_04835-04899_11', 'star...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0001_005_06437-06501_8.mp4</td>\n      <td></td>\n      <td>64</td>\n      <td>center</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n      <td>{'sample_id': '0001_005_06437-06501_8', 'start...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001_007_06547-06611_8.mp4</td>\n      <td></td>\n      <td>64</td>\n      <td>center</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n      <td>{'sample_id': '0001_007_06547-06611_8', 'start...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001_009_06620-06684_8.mp4</td>\n      <td></td>\n      <td>64</td>\n      <td>center</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n      <td>{'sample_id': '0001_009_06620-06684_8', 'start...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T01:55:34.604308Z",
     "start_time": "2024-05-13T01:55:34.584324100Z"
    }
   },
   "id": "d5d0c84fd07f801a"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "def get_class_weights(df,feature_names, alpha=10, beta=2):\n",
    "    class_weights = {}\n",
    "    positive_weights = {}\n",
    "    negative_weights = {}\n",
    "    # N = len(df)\n",
    "    n_features = len(feature_names)\n",
    "\n",
    "    N = np.sum(df[feature_names].to_numpy())\n",
    "    for label in feature_names:\n",
    "        if label in df.columns:\n",
    "            positive_weights[label] = np.log((N+n_features) /(alpha * (sum(df[label] == 1))+1)*beta)\n",
    "            negative_weights[label] = np.log((N+n_features) /(alpha * (sum(df[label] == 0))+1)*beta)\n",
    "        else:\n",
    "            positive_weights[label] = 0\n",
    "            negative_weights[label] = 0\n",
    "\n",
    "\n",
    "            \n",
    "    # class_weights['positive_weights'] = pd.DataFrame.from_dict(positive_weights)\n",
    "    # class_weights['negative_weights'] = pd.DataFrame.from_dict(negative_weights)\n",
    "    class_weights = pd.DataFrame(zip(positive_weights.keys(),positive_weights.values(), negative_weights.values()),columns=['class','positive_weights','negative_weights'])        \n",
    "    class_weights['method'] = 'inv'\n",
    "    return class_weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T02:00:34.563572800Z",
     "start_time": "2024-05-13T02:00:34.556538600Z"
    }
   },
   "id": "5afe1121ec0ebf19"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T02:00:35.683389Z",
     "start_time": "2024-05-13T02:00:35.680860900Z"
    }
   },
   "id": "2da64932a558217"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "data": {
      "text/plain": "    class  positive_weights  negative_weights\n0       0          3.171735         -0.909245\n1       1          2.797769         -0.901556\n2       2          1.542723         -0.837499\n3       3          4.367986         -0.920960\n4       4          0.206402         -0.537004\n5       5          3.342496         -0.911893\n6       6          2.112654         -0.876910\n7       7          1.080015         -0.781519\n8       8          0.131097         -0.499104\n9       9          4.160347         -0.919795\n10     10          4.258787         -0.920378\n11     11          1.535905         -0.836865\n12     12          2.846959         -0.902743\n13     13          2.573027         -0.895302\n14     14          4.311897         -0.920669\n15     15          3.523439         -0.914241\n16     16          2.925602         -0.904520",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>positive_weights</th>\n      <th>negative_weights</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3.171735</td>\n      <td>-0.909245</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2.797769</td>\n      <td>-0.901556</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>1.542723</td>\n      <td>-0.837499</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>4.367986</td>\n      <td>-0.920960</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>0.206402</td>\n      <td>-0.537004</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>5</td>\n      <td>3.342496</td>\n      <td>-0.911893</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>6</td>\n      <td>2.112654</td>\n      <td>-0.876910</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>7</td>\n      <td>1.080015</td>\n      <td>-0.781519</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>8</td>\n      <td>0.131097</td>\n      <td>-0.499104</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>9</td>\n      <td>4.160347</td>\n      <td>-0.919795</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>10</td>\n      <td>4.258787</td>\n      <td>-0.920378</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>11</td>\n      <td>1.535905</td>\n      <td>-0.836865</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>12</td>\n      <td>2.846959</td>\n      <td>-0.902743</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>13</td>\n      <td>2.573027</td>\n      <td>-0.895302</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>14</td>\n      <td>4.311897</td>\n      <td>-0.920669</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>15</td>\n      <td>3.523439</td>\n      <td>-0.914241</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>16</td>\n      <td>2.925602</td>\n      <td>-0.904520</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_weights = pd.DataFrame(df['multihot_labels'].tolist(), columns=range(len(df['multihot_labels'].iloc[0])))\n",
    "class_weights = get_class_weights(df_weights,feature_names=range(17), alpha=3, beta=1)\n",
    "class_weights = class_weights.drop('method',axis=1)\n",
    "class_weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T02:02:54.693682100Z",
     "start_time": "2024-05-13T02:02:54.674977400Z"
    }
   },
   "id": "edf32ca96fc741c2"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [],
   "source": [
    "save_folder = r'C:\\Users\\gutzc\\GitHub\\human_micro_gesture_classifier\\miga\\datasets\\resampled_64'\n",
    "\n",
    "df_train.to_csv(osp.join(save_folder, 'train.csv'))\n",
    "# df_test.to_csv(osp.join(save_folder, 'test.csv'))\n",
    "df_val.to_csv(osp.join(save_folder, 'val.csv'))\n",
    "class_weights.to_csv(osp.join(save_folder, 'weights.csv'))\n",
    "\n",
    "import json\n",
    "wrapped_data = {'data': class_weights.to_dict(orient='records')}\n",
    "\n",
    "# Save wrapped data as JSON\n",
    "with open(osp.join(save_folder, 'weights.json'), 'w') as json_file:\n",
    "    json.dump(wrapped_data, json_file, indent=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T02:05:11.315779900Z",
     "start_time": "2024-05-13T02:05:11.070468800Z"
    }
   },
   "id": "ff67c1ef18144e50"
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "                          filenames folder_name  durations    view  \\\n0       0001_001_00831-00895_14.mp4                     64  center   \n1       0001_002_01697-01761_11.mp4                     64  center   \n2        0001_004_06317-06381_7.mp4                     64  center   \n3        0001_006_06501-06565_8.mp4                     64  center   \n4        0001_008_06611-06675_8.mp4                     64  center   \n...                             ...         ...        ...     ...   \n3091     0032_011_14345-14409_5.mp4                     64  center   \n3092   0032_012_14357-14421_5-7.mp4                     64  center   \n3093     0032_013_16889-16953_7.mp4                     64  center   \n3094    0032_014_16953-17017_11.mp4                     64  center   \n3095  0032_015_16938-17002_11-7.mp4                     64  center   \n\n                                                 labels  \\\n0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n1     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n2     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n3     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n4     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n...                                                 ...   \n3091  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...   \n3092  [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...   \n3093  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n3094  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n3095  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n\n                                               metadata  \n0     {'sample_id': '0001_001_00831-00895_14', 'star...  \n1     {'sample_id': '0001_002_01697-01761_11', 'star...  \n2     {'sample_id': '0001_004_06317-06381_7', 'start...  \n3     {'sample_id': '0001_006_06501-06565_8', 'start...  \n4     {'sample_id': '0001_008_06611-06675_8', 'start...  \n...                                                 ...  \n3091  {'sample_id': '0032_011_14345-14409_5', 'start...  \n3092  {'sample_id': '0032_012_14357-14421_5-7', 'sta...  \n3093  {'sample_id': '0032_013_16889-16953_7', 'start...  \n3094  {'sample_id': '0032_014_16953-17017_11', 'star...  \n3095  {'sample_id': '0032_015_16938-17002_11-7', 'st...  \n\n[3096 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filenames</th>\n      <th>folder_name</th>\n      <th>durations</th>\n      <th>view</th>\n      <th>labels</th>\n      <th>metadata</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0001_001_00831-00895_14.mp4</td>\n      <td></td>\n      <td>64</td>\n      <td>center</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>{'sample_id': '0001_001_00831-00895_14', 'star...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0001_002_01697-01761_11.mp4</td>\n      <td></td>\n      <td>64</td>\n      <td>center</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>{'sample_id': '0001_002_01697-01761_11', 'star...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0001_004_06317-06381_7.mp4</td>\n      <td></td>\n      <td>64</td>\n      <td>center</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n      <td>{'sample_id': '0001_004_06317-06381_7', 'start...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0001_006_06501-06565_8.mp4</td>\n      <td></td>\n      <td>64</td>\n      <td>center</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n      <td>{'sample_id': '0001_006_06501-06565_8', 'start...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0001_008_06611-06675_8.mp4</td>\n      <td></td>\n      <td>64</td>\n      <td>center</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n      <td>{'sample_id': '0001_008_06611-06675_8', 'start...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3091</th>\n      <td>0032_011_14345-14409_5.mp4</td>\n      <td></td>\n      <td>64</td>\n      <td>center</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, ...</td>\n      <td>{'sample_id': '0032_011_14345-14409_5', 'start...</td>\n    </tr>\n    <tr>\n      <th>3092</th>\n      <td>0032_012_14357-14421_5-7.mp4</td>\n      <td></td>\n      <td>64</td>\n      <td>center</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, ...</td>\n      <td>{'sample_id': '0032_012_14357-14421_5-7', 'sta...</td>\n    </tr>\n    <tr>\n      <th>3093</th>\n      <td>0032_013_16889-16953_7.mp4</td>\n      <td></td>\n      <td>64</td>\n      <td>center</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n      <td>{'sample_id': '0032_013_16889-16953_7', 'start...</td>\n    </tr>\n    <tr>\n      <th>3094</th>\n      <td>0032_014_16953-17017_11.mp4</td>\n      <td></td>\n      <td>64</td>\n      <td>center</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>{'sample_id': '0032_014_16953-17017_11', 'star...</td>\n    </tr>\n    <tr>\n      <th>3095</th>\n      <td>0032_015_16938-17002_11-7.mp4</td>\n      <td></td>\n      <td>64</td>\n      <td>center</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n      <td>{'sample_id': '0032_015_16938-17002_11-7', 'st...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3096 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T05:42:01.118652Z",
     "start_time": "2024-05-13T05:42:01.084502100Z"
    }
   },
   "id": "1fb18c1cf5c59737"
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "outputs": [
    {
     "data": {
      "text/plain": "(17,)"
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = df_train.labels\n",
    "s = labels[0].shape\n",
    "s"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T05:42:56.410948400Z",
     "start_time": "2024-05-13T05:42:56.386647700Z"
    }
   },
   "id": "3223bd10cc148695"
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "outputs": [],
   "source": [
    "shapes = [l.shape for l in labels]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T05:43:27.147942700Z",
     "start_time": "2024-05-13T05:43:27.140908100Z"
    }
   },
   "id": "e685d7320f4807df"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([a != s for a in shapes])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T05:44:11.835502500Z",
     "start_time": "2024-05-13T05:44:11.829987Z"
    }
   },
   "id": "831422bf29ec18ce"
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import dyadic_communication\n",
    "from importlib import reload\n",
    "import debug_model\n",
    "import run_videomae_vis_v2\n",
    "import mpigroup.const as const\n",
    "reload(dyadic_communication)\n",
    "reload(debug_model)\n",
    "reload(run_videomae_vis_v2)\n",
    "cropping_map = const.cropping_map\n",
    "import torch\n",
    "from argparse import Namespace\n",
    "import mpigroup.const as const"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T07:03:25.819691400Z",
     "start_time": "2024-05-13T07:03:25.800927300Z"
    }
   },
   "id": "32e6ccdb86d8b1be"
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "data_path= r'C:\\Users\\gutzc\\GitHub\\human_micro_gesture_classifier\\miga_dataset\\SMG_RGB_Phase1\\split_files_video'\n",
    "experiment_folder = r'C:\\Users\\gutzc\\GitHub\\human_micro_gesture_classifier\\miga\\datasets\\resampled_64'\n",
    "args = debug_model.args\n",
    "args.anno_path = osp.join(experiment_folder,'val.csv')\n",
    "args.data_path = data_path\n",
    "args.data_root = data_path\n",
    "args.mode = 'validation'\n",
    "args.test_mode = False\n",
    "dataset = dyadic_communication.DyadicvideoClsDataset(\n",
    "          anno_path=args.anno_path,\n",
    "            data_path=args.data_path,\n",
    "            mode=args.mode,\n",
    "            clip_len=1,\n",
    "            num_segment=args.num_frames,\n",
    "            test_num_segment=args.test_num_segment,\n",
    "            test_num_crop=args.test_num_crop,\n",
    "            num_crop=1 if not args.test_mode else 3,\n",
    "            keep_aspect_ratio=True,\n",
    "            crop_size=args.input_size,\n",
    "            short_side_size=args.short_side_size,\n",
    "            new_height=224,\n",
    "            new_width=224,\n",
    "            view_crop_mapping=cropping_map,\n",
    "            corner_crop_size=None,\n",
    "            data_root=args.data_root,\n",
    "            limit_data=None,    \n",
    "            args=args)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T07:03:12.401669500Z",
     "start_time": "2024-05-13T07:03:12.366458200Z"
    }
   },
   "id": "c6d2abca898a375"
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "\n",
    "data = DataLoader(dataset=dataset, batch_size=5, shuffle=True)\n",
    "iterdata = iter(data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T07:03:13.739464600Z",
     "start_time": "2024-05-13T07:03:13.731721900Z"
    }
   },
   "id": "c14cc1ba35505609"
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 16, 224, 224])\n",
      "tensor([[0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
      "       dtype=torch.float64)\n",
      "[[('C:\\\\Users\\\\gutzc\\\\GitHub\\\\human_micro_gesture_classifier\\\\miga_dataset\\\\SMG_RGB_Phase1\\\\split_files_video\\\\0015_065_06852-06916_4', 'C:\\\\Users\\\\gutzc\\\\GitHub\\\\human_micro_gesture_classifier\\\\miga_dataset\\\\SMG_RGB_Phase1\\\\split_files_video\\\\0008_017_05321-05385_7', 'C:\\\\Users\\\\gutzc\\\\GitHub\\\\human_micro_gesture_classifier\\\\miga_dataset\\\\SMG_RGB_Phase1\\\\split_files_video\\\\0015_083_08743-08807_3', 'C:\\\\Users\\\\gutzc\\\\GitHub\\\\human_micro_gesture_classifier\\\\miga_dataset\\\\SMG_RGB_Phase1\\\\split_files_video\\\\0004_149_24658-24722_4', 'C:\\\\Users\\\\gutzc\\\\GitHub\\\\human_micro_gesture_classifier\\\\miga_dataset\\\\SMG_RGB_Phase1\\\\split_files_video\\\\0015_109_12570-12634_4')], (\"{'sample_id': '0015_065_06852-06916_4', 'start_frame': 6792, 'end_frame': 6856, 'label': [4], 'view': 'center', 'filenames': '0015_065_06852-06916_4.mp4', 'durations': 64}\", \"{'sample_id': '0008_017_05321-05385_7', 'start_frame': 5242, 'end_frame': 5306, 'label': [7], 'view': 'center', 'filenames': '0008_017_05321-05385_7.mp4', 'durations': 64}\", \"{'sample_id': '0015_083_08743-08807_3', 'start_frame': 8428, 'end_frame': 8492, 'label': [3], 'view': 'center', 'filenames': '0015_083_08743-08807_3.mp4', 'durations': 64}\", \"{'sample_id': '0004_149_24658-24722_4', 'start_frame': 24594, 'end_frame': 24658, 'label': [4], 'view': 'center', 'filenames': '0004_149_24658-24722_4.mp4', 'durations': 64}\", \"{'sample_id': '0015_109_12570-12634_4', 'start_frame': 12506, 'end_frame': 12570, 'label': [4], 'view': 'center', 'filenames': '0015_109_12570-12634_4.mp4', 'durations': 64}\"), [], []]\n"
     ]
    }
   ],
   "source": [
    "d = next(iterdata)\n",
    "print(d[0].shape)\n",
    "print(d[1])\n",
    "print(d[2:])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T07:03:18.027444100Z",
     "start_time": "2024-05-13T07:03:14.610447900Z"
    }
   },
   "id": "d64969e1638750cd"
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model: pretrain_videomae_base_patch16_224_densepose_dual\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\Project-mpg microgesture\\\\pretrained\\\\pretrained\\\\MPIIGroupInteraction\\\\k400_finetune_videomae_pretrain_dual_2_patch16_224_frame_16x4_tube_mask_ratio_0.9_e100\\\\checkpoint-99.pth'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[133], line 31\u001B[0m\n\u001B[0;32m     13\u001B[0m args \u001B[38;5;241m=\u001B[39m Namespace(\n\u001B[0;32m     14\u001B[0m         image_batch\u001B[38;5;241m=\u001B[39mimage_batch,\n\u001B[0;32m     15\u001B[0m         save_path\u001B[38;5;241m=\u001B[39msave_folder, \u001B[38;5;66;03m# list\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     26\u001B[0m         densepose\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m     27\u001B[0m         drop_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0\u001B[39m)\n\u001B[0;32m     29\u001B[0m model \u001B[38;5;241m=\u001B[39m run_videomae_vis_v2\u001B[38;5;241m.\u001B[39mget_model(args\u001B[38;5;241m=\u001B[39margs) \n\u001B[1;32m---> 31\u001B[0m checkpoint \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mload(args\u001B[38;5;241m.\u001B[39mmodel_path, map_location\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     32\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(checkpoint[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     33\u001B[0m model\u001B[38;5;241m.\u001B[39meval()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\electro\\Lib\\site-packages\\torch\\serialization.py:997\u001B[0m, in \u001B[0;36mload\u001B[1;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001B[0m\n\u001B[0;32m    994\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m pickle_load_args\u001B[38;5;241m.\u001B[39mkeys():\n\u001B[0;32m    995\u001B[0m     pickle_load_args[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mencoding\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m--> 997\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _open_file_like(f, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m opened_file:\n\u001B[0;32m    998\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_zipfile(opened_file):\n\u001B[0;32m    999\u001B[0m         \u001B[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001B[39;00m\n\u001B[0;32m   1000\u001B[0m         \u001B[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001B[39;00m\n\u001B[0;32m   1001\u001B[0m         \u001B[38;5;66;03m# reset back to the original position.\u001B[39;00m\n\u001B[0;32m   1002\u001B[0m         orig_position \u001B[38;5;241m=\u001B[39m opened_file\u001B[38;5;241m.\u001B[39mtell()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\electro\\Lib\\site-packages\\torch\\serialization.py:444\u001B[0m, in \u001B[0;36m_open_file_like\u001B[1;34m(name_or_buffer, mode)\u001B[0m\n\u001B[0;32m    442\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_open_file_like\u001B[39m(name_or_buffer, mode):\n\u001B[0;32m    443\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m _is_path(name_or_buffer):\n\u001B[1;32m--> 444\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _open_file(name_or_buffer, mode)\n\u001B[0;32m    445\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    446\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01min\u001B[39;00m mode:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\electro\\Lib\\site-packages\\torch\\serialization.py:425\u001B[0m, in \u001B[0;36m_open_file.__init__\u001B[1;34m(self, name, mode)\u001B[0m\n\u001B[0;32m    424\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, mode):\n\u001B[1;32m--> 425\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mopen\u001B[39m(name, mode))\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'D:\\\\Project-mpg microgesture\\\\pretrained\\\\pretrained\\\\MPIIGroupInteraction\\\\k400_finetune_videomae_pretrain_dual_2_patch16_224_frame_16x4_tube_mask_ratio_0.9_e100\\\\checkpoint-99.pth'"
     ]
    }
   ],
   "source": [
    "model_dict = {\n",
    "    'experiment':'MPIG_densepose_dual_2',\n",
    "    'description':'MPIG_densepose_dual - videoMAE-K400 , same as K400 but then was finetuned on MPIGroupInteractions dataset (train set) for 100 epochs, with denspose as additional decoding target',\n",
    "    'checkpoint_path':r'D:\\Project-mpg microgesture\\pretrained\\pretrained\\MPIIGroupInteraction\\k400_finetune_videomae_pretrain_dual_2_patch16_224_frame_16x4_tube_mask_ratio_0.9_e100\\checkpoint-99.pth',\n",
    "    'model_name':'pretrain_videomae_base_patch16_224_densepose_dual',\n",
    "}\n",
    "\n",
    "image_batch = d[0]\n",
    "save_folder = osp.join('videos')\n",
    "model_path = model_dict['checkpoint_path']\n",
    "model_name = model_dict['model_name']\n",
    "\n",
    "args = Namespace(\n",
    "        image_batch=image_batch,\n",
    "        save_path=save_folder, # list\n",
    "        model_path=model_path, \n",
    "        mask_type='tube',\n",
    "        num_frames=16,\n",
    "        sampling_rate=4,\n",
    "        decoder_depth=4,\n",
    "        input_size=224,\n",
    "        device='cuda:0',\n",
    "        imagenet_default_mean_and_std=True,\n",
    "        mask_ratio=0,\n",
    "        model=model_name,\n",
    "        densepose=True,\n",
    "        drop_path=0.0)\n",
    "\n",
    "model = run_videomae_vis_v2.get_model(args=args) \n",
    "\n",
    "checkpoint = torch.load(args.model_path, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T07:03:47.199782700Z",
     "start_time": "2024-05-13T07:03:42.776359900Z"
    }
   },
   "id": "e5e5c150bc121cc5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ff9e4812f1f6e73"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
