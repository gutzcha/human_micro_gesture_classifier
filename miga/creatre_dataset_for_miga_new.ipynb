{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T15:17:56.955191100Z",
     "start_time": "2024-05-12T15:17:56.943643900Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import os.path as osp\n",
    "from glob import glob\n",
    "import sys\n",
    "from const import ID2LABELS_SMG_SHORT as LABEL2ID\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.insert(0, '..')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'C:\\\\Users\\\\gutzc\\\\GitHub\\\\human_micro_gesture_classifier\\\\miga'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T15:17:56.968619500Z",
     "start_time": "2024-05-12T15:17:56.955191100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T15:17:57.209773400Z",
     "start_time": "2024-05-12T15:17:57.188761600Z"
    }
   },
   "outputs": [],
   "source": [
    "path_to_root_folder = osp.join(r'..\\miga_dataset\\smg_data_phase1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2452\n",
      "637\n"
     ]
    }
   ],
   "source": [
    "def load_and_concat(path_to_root_folder, dataset):\n",
    "    all_paths = glob(osp.join(path_to_root_folder,f'smg_skeleton_{dataset}','*','*labels.csv' ))\n",
    "    df_list = []\n",
    "    for p in all_paths:\n",
    "        df_temp = pd.read_csv(p, header=None)\n",
    "        df_temp.columns = ['labels','start_frame','end_frame']\n",
    "        df_temp['labels_txt'] = df_temp['labels'].apply(lambda x: LABEL2ID[x])\n",
    "        df_list.append(df_temp)\n",
    "        \n",
    "    return pd.concat(df_list)\n",
    "\n",
    "df_train_raw = load_and_concat(path_to_root_folder, dataset='train')\n",
    "df_val_raw = load_and_concat(path_to_root_folder, dataset='validate')\n",
    "\n",
    "df_train_raw['dataset'] = 'train'\n",
    "df_val_raw['dataset'] = 'validation'\n",
    "df_all = pd.concat([df_train_raw, df_val_raw])\n",
    "print(len(df_train_raw))\n",
    "print(len(df_val_raw))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T15:17:58.271849Z",
     "start_time": "2024-05-12T15:17:58.169428700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gutzc\\anaconda3\\Lib\\site-packages\\seaborn\\axisgrid.py:118: UserWarning: The figure layout has changed to tight\n",
      "  self._figure.tight_layout(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": "<seaborn.axisgrid.FacetGrid at 0x2005b2cbfd0>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 1000x500 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(df_all, x=\"labels\", col=\"dataset\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T15:17:59.870073300Z",
     "start_time": "2024-05-12T15:17:59.007574Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-12T15:17:59.988046300Z",
     "start_time": "2024-05-12T15:17:59.973034100Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Structure of the final dataset: filename, labels\n",
    "# def get_video_list(files_folder):\n",
    "#     all_files = glob(osp.join(files_folder, '*.mp4'))\n",
    "#     base_names = [osp.basename(f) for f in all_files]\n",
    "#     sample_id = [int(osp.splitext(f)[0].split('-')[0]) for f in base_names]\n",
    "#     view = [(osp.splitext(f)[0].split('-video')[-1]) for f in base_names]\n",
    "#     df = pd.DataFrame(zip(all_files, base_names, sample_id, view), columns=['filenames', 'base_name', 'sample_id', 'view'])\n",
    "#     return df\n",
    "# df_train_files = get_video_list(files_folder=train_files_folder)\n",
    "# df_val_files = get_video_list(files_folder=val_files_folder)\n",
    "# # file_sample_ids.sort()\n",
    "# # file_sample_ids\n",
    "# # df_train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'paths'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3652\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 3653\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3654\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'paths'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 33\u001B[0m\n\u001B[0;32m     29\u001B[0m     df_out[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m metadata\u001B[38;5;241m.\u001B[39mto_dict(orient\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrecords\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m df_out, new_columns, one_hot_encoded\n\u001B[1;32m---> 33\u001B[0m df_train,new_columns, train_one_hot_encoded \u001B[38;5;241m=\u001B[39m convert_df(df_train_raw)\n\u001B[0;32m     34\u001B[0m df_val, _, val_one_hot_encoded \u001B[38;5;241m=\u001B[39m convert_df(df_val_raw)\n",
      "Cell \u001B[1;32mIn[7], line 5\u001B[0m, in \u001B[0;36mconvert_df\u001B[1;34m(df_in)\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconvert_df\u001B[39m(df_in):\n\u001B[0;32m      3\u001B[0m     df_out \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame()\n\u001B[1;32m----> 5\u001B[0m     df_out[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfilenames\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df_in[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpaths\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: osp\u001B[38;5;241m.\u001B[39mbasename(x))\n\u001B[0;32m      6\u001B[0m     df_out[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfolder_name\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df_in[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpaths\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28;01mlambda\u001B[39;00m x: x\u001B[38;5;241m.\u001B[39msplit(\u001B[38;5;124m'\u001B[39m\u001B[38;5;130;01m\\\\\u001B[39;00m\u001B[38;5;124m'\u001B[39m)[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m2\u001B[39m])\n\u001B[0;32m      7\u001B[0m     df_out[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdurations\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m df_in[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdurations\u001B[39m\u001B[38;5;124m'\u001B[39m]\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3759\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   3760\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 3761\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mget_loc(key)\n\u001B[0;32m   3762\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   3763\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   3653\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[0;32m   3654\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m-> 3655\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m   3656\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[0;32m   3657\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[0;32m   3658\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[0;32m   3659\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[0;32m   3660\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'paths'"
     ]
    }
   ],
   "source": [
    "def convert_df(df_in):\n",
    "        \n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    df_out['filenames'] = df_in['paths'].apply(lambda x: osp.basename(x))\n",
    "    df_out['folder_name'] = df_in['paths'].apply(lambda x: x.split('\\\\')[-2])\n",
    "    df_out['durations'] = df_in['durations']\n",
    "    \n",
    "    df_out['view'] = 'center'\n",
    "    metadata = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    metadata['sample_id'] = df_out['filenames'].apply(lambda x: x.split('.')[0].replace('Sample','').replace('color_',''))\n",
    "    metadata['start_frame'] = df_in['start_frame']\n",
    "    metadata['end_frame'] = df_in['end_frame']\n",
    "    metadata['label_txt'] = df_in['label'].apply(lambda x: LABEL2ID[x])\n",
    "    metadata['label']= df_in['label']\n",
    "    metadata['view'] =  df_out['view']\n",
    "    metadata['filenames'] = df_out['filenames']\n",
    "    metadata['durations'] = df_out['durations']\n",
    "    cat = df_in['label']\n",
    "    categories = list(LABEL2ID.keys())\n",
    "    one_hot_encoded = pd.get_dummies(cat.astype(pd.CategoricalDtype(categories=categories)))\n",
    "    \n",
    "    new_columns = one_hot_encoded.columns.to_list()\n",
    "    one_hot_encoded = one_hot_encoded.astype(float)\n",
    "    df_out['labels'] = one_hot_encoded.values.tolist()\n",
    "    # df_out['labels'] = df_in['label'] - 1\n",
    "    df_out['metadata'] = metadata.to_dict(orient='records')\n",
    "    \n",
    "    return df_out, new_columns, one_hot_encoded\n",
    "\n",
    "df_train,new_columns, train_one_hot_encoded = convert_df(df_train_raw)\n",
    "df_val, _, val_one_hot_encoded = convert_df(df_val_raw)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-12T15:18:03.076388600Z",
     "start_time": "2024-05-12T15:18:00.296389700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(df_val.iloc[0]['labels'])\n",
    "print(len(df_val.iloc[0]['labels']))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-12T15:18:03.077389600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-12T15:18:03.078390600Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_folder = r'D:\\Project-mpg microgesture\\human_micro_gesture_classifier\\scripts\\miga_smg'\n",
    "run_name = 'videomae_vit_base_patch16_224_kinetic_400_densepose_dual_resample'\n",
    "\n",
    "os.makedirs(osp.join(experiment_folder, run_name), exist_ok=True)\n",
    "os.makedirs(osp.join(experiment_folder, run_name,'dataset'), exist_ok=True)\n",
    "\n",
    "df_val.to_csv(osp.join(experiment_folder,'val.csv'))\n",
    "df_train.to_csv(osp.join(experiment_folder,'train.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T11:29:28.332012700Z",
     "start_time": "2024-05-08T11:29:26.276939Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Project-mpg microgesture\\human_micro_gesture_classifier\\miga\\..\\modeling_finetune.py:306: UserWarning: Overwriting vit_small_patch16_224 in registry with modeling_finetune.vit_small_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def vit_small_patch16_224(pretrained=False, **kwargs):\n",
      "D:\\Project-mpg microgesture\\human_micro_gesture_classifier\\miga\\..\\modeling_finetune.py:315: UserWarning: Overwriting vit_base_patch16_224 in registry with modeling_finetune.vit_base_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def vit_base_patch16_224(pretrained=False, **kwargs):\n",
      "D:\\Project-mpg microgesture\\human_micro_gesture_classifier\\miga\\..\\modeling_finetune.py:324: UserWarning: Overwriting vit_base_patch16_384 in registry with modeling_finetune.vit_base_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def vit_base_patch16_384(pretrained=False, **kwargs):\n",
      "D:\\Project-mpg microgesture\\human_micro_gesture_classifier\\miga\\..\\modeling_finetune.py:333: UserWarning: Overwriting vit_large_patch16_224 in registry with modeling_finetune.vit_large_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def vit_large_patch16_224(pretrained=False, **kwargs):\n",
      "D:\\Project-mpg microgesture\\human_micro_gesture_classifier\\miga\\..\\modeling_finetune.py:342: UserWarning: Overwriting vit_large_patch16_384 in registry with modeling_finetune.vit_large_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def vit_large_patch16_384(pretrained=False, **kwargs):\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import dyadic_communication\n",
    "from importlib import reload\n",
    "import debug_model\n",
    "import run_videomae_vis_v2\n",
    "\n",
    "reload(dyadic_communication)\n",
    "reload(debug_model)\n",
    "reload(run_videomae_vis_v2)\n",
    "\n",
    "from argparse import Namespace\n",
    "import mpigroup.const as const\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T10:36:33.174771600Z",
     "start_time": "2024-05-07T10:36:33.142790600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'front1': 'tr', 'front2': 'tl', 'right': 'bl', 'left': 'br', 'center': 'mm'}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(const)\n",
    "cropping_map = const.cropping_map\n",
    "cropping_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T10:36:35.275444600Z",
     "start_time": "2024-05-07T10:36:33.752450100Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\Project-mpg microgesture\\\\human_micro_gesture_classifier\\\\scripts\\\\miga_smg\\\\val.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m args\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalidation\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      8\u001B[0m args\u001B[38;5;241m.\u001B[39mtest_mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mdyadic_communication\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDyadicvideoClsDataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m          \u001B[49m\u001B[43manno_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43manno_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdata_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m            \u001B[49m\u001B[43mclip_len\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnum_segment\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_frames\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtest_num_segment\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_num_segment\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtest_num_crop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_num_crop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnum_crop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_mode\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m            \u001B[49m\u001B[43mkeep_aspect_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcrop_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m            \u001B[49m\u001B[43mshort_side_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshort_side_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnew_height\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m224\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnew_width\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m224\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m            \u001B[49m\u001B[43mview_crop_mapping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcropping_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcorner_crop_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdata_root\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_root\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[43m            \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Project-mpg microgesture\\human_micro_gesture_classifier\\miga\\..\\dyadic_communication.py:54\u001B[0m, in \u001B[0;36mDyadicvideoClsDataset.__init__\u001B[1;34m(self, anno_path, data_path, mode, clip_len, crop_size, short_side_size, new_height, new_width, keep_aspect_ratio, num_segment, num_crop, test_num_segment, test_num_crop, view_crop_mapping, corner_crop_size, data_root, limit_data, args, **kwargs)\u001B[0m\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnable to import `decord` which is required to read videos.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39manno_path, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m---> 54\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43manno_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     56\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39manno_path\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\micro\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m   1014\u001B[0m     dialect,\n\u001B[0;32m   1015\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m   1023\u001B[0m )\n\u001B[0;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\micro\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    617\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    619\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 620\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    622\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\micro\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1617\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1619\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1620\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\micro\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1878\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1879\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1880\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1881\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1882\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1883\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1884\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1885\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1886\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1887\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1888\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1889\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1890\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1891\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\micro\\lib\\site-packages\\pandas\\io\\common.py:873\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    868\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    869\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    870\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    871\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    872\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 873\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    874\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    875\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    876\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    878\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    879\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    880\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    881\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    882\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'D:\\\\Project-mpg microgesture\\\\human_micro_gesture_classifier\\\\scripts\\\\miga_smg\\\\val.csv'"
     ]
    }
   ],
   "source": [
    "data_path= r'D:\\Project-mpg microgesture\\smg\\smg_split_files'\n",
    "\n",
    "args = debug_model.args\n",
    "args.anno_path = osp.join(experiment_folder,'val.csv')\n",
    "args.data_path = data_path\n",
    "args.data_root = data_path\n",
    "args.mode = 'validation'\n",
    "args.test_mode = False\n",
    "dataset = dyadic_communication.DyadicvideoClsDataset(\n",
    "          anno_path=args.anno_path,\n",
    "            data_path=args.data_path,\n",
    "            mode=args.mode,\n",
    "            clip_len=1,\n",
    "            num_segment=args.num_frames,\n",
    "            test_num_segment=args.test_num_segment,\n",
    "            test_num_crop=args.test_num_crop,\n",
    "            num_crop=1 if not args.test_mode else 3,\n",
    "            keep_aspect_ratio=True,\n",
    "            crop_size=args.input_size,\n",
    "            short_side_size=args.short_side_size,\n",
    "            new_height=224,\n",
    "            new_width=224,\n",
    "            view_crop_mapping=cropping_map,\n",
    "            corner_crop_size=None,\n",
    "            data_root=args.data_root,\n",
    "            args=args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T12:58:36.008172700Z",
     "start_time": "2024-05-06T12:58:35.994171300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:58:37.324251600Z",
     "start_time": "2024-05-06T12:58:37.317251500Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "data = DataLoader(dataset=dataset, batch_size=5, shuffle=True)\n",
    "iterdata = iter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:58:40.858344500Z",
     "start_time": "2024-05-06T12:58:37.814344100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 16, 224, 224])\n",
      "tensor([6, 6, 6, 6, 2])\n",
      "[('D:\\\\Project-mpg microgesture\\\\smg\\\\smg_split_files\\\\validation\\\\Sample0033_color_0082', 'D:\\\\Project-mpg microgesture\\\\smg\\\\smg_split_files\\\\validation\\\\Sample0031_color_0044', 'D:\\\\Project-mpg microgesture\\\\smg\\\\smg_split_files\\\\validation\\\\Sample0033_color_0159', 'D:\\\\Project-mpg microgesture\\\\smg\\\\smg_split_files\\\\validation\\\\Sample0033_color_0005', 'D:\\\\Project-mpg microgesture\\\\smg\\\\smg_split_files\\\\validation\\\\Sample0033_color_0113'), {'sample_id': ['0033_0082', '0031_0044', '0033_0159', '0033_0005', '0033_0113'], 'start_frame': tensor([ 6978, 11895, 12230,   766,  8978]), 'end_frame': tensor([ 7023, 12078, 12316,   776,  9020]), 'label_txt': ['Arms akimbo', 'Arms akimbo', 'Arms akimbo', 'Arms akimbo', 'Moving legs'], 'view': ['center', 'center', 'center', 'center', 'center'], 'filenames': ['Sample0033_color_0082.mp4', 'Sample0031_color_0044.mp4', 'Sample0033_color_0159.mp4', 'Sample0033_color_0005.mp4', 'Sample0033_color_0113.mp4'], 'durations': tensor([ 45, 183,  86,  10,  42])}, [], []]\n"
     ]
    }
   ],
   "source": [
    "d = next(iterdata)\n",
    "print(d[0].shape)\n",
    "print(d[1])\n",
    "print(d[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:58:42.529344700Z",
     "start_time": "2024-05-06T12:58:40.842352800Z"
    }
   },
   "outputs": [],
   "source": [
    "reload(run_videomae_vis_v2)\n",
    "\n",
    "vids = d[0]\n",
    "labels = d[1]\n",
    "label_txt = d[3]['label_txt']\n",
    "fnames = d[3]['filenames']\n",
    "\n",
    "for vid,label, txt_label, fname in zip(vids,labels, label_txt, fnames):\n",
    "       \n",
    "    # ret = get_activities(feature_names, label)\n",
    "\n",
    "    txt =  '\\n'.join([fname ,txt_label])\n",
    "    \n",
    "    vid = run_videomae_vis_v2.unnormalize_frames(vid)\n",
    "    run_videomae_vis_v2.save_video(vid, osp.join('testing_'+fname), txt=txt)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:58:42.545355900Z",
     "start_time": "2024-05-06T12:58:42.530347600Z"
    }
   },
   "outputs": [],
   "source": [
    "# video_path = osp.join(path_to_root_folder,'clips_val','05942-video1.mp4')\n",
    "# video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:58:42.571352400Z",
     "start_time": "2024-05-06T12:58:42.548346300Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    'experiment':'MPIG_densepose_dual_2',\n",
    "    'description':'MPIG_densepose_dual - videoMAE-K400 , same as K400 but then was finetuned on MPIGroupInteractions dataset (train set) for 100 epochs, with denspose as additional decoding target',\n",
    "    'checkpoint_path':r'D:\\Project-mpg microgesture\\pretrained\\pretrained\\MPIIGroupInteraction\\k400_finetune_videomae_pretrain_dual_2_patch16_224_frame_16x4_tube_mask_ratio_0.9_e100\\checkpoint-99.pth',\n",
    "    'model_name':'pretrain_videomae_base_patch16_224_densepose_dual',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:58:42.580344200Z",
     "start_time": "2024-05-06T12:58:42.566348700Z"
    }
   },
   "outputs": [],
   "source": [
    "image_batch = d[0]\n",
    "save_folder = osp.join('videos')\n",
    "model_path = model_dict['checkpoint_path']\n",
    "model_name = model_dict['model_name']\n",
    "\n",
    "args = Namespace(\n",
    "        image_batch=image_batch,\n",
    "        save_path=save_folder, # list\n",
    "        model_path=model_path, \n",
    "        mask_type='tube',\n",
    "        num_frames=16,\n",
    "        sampling_rate=4,\n",
    "        decoder_depth=4,\n",
    "        input_size=224,\n",
    "        device='cuda:0',\n",
    "        imagenet_default_mean_and_std=True,\n",
    "        mask_ratio=0,\n",
    "        model=model_name,\n",
    "        densepose=True,\n",
    "        drop_path=0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:58:47.064376800Z",
     "start_time": "2024-05-06T12:58:42.581345100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model: pretrain_videomae_base_patch16_224_densepose_dual\n"
     ]
    },
    {
     "data": {
      "text/plain": "PretrainVisionTransformerMultiOutout(\n  (encoder): PretrainVisionTransformerEncoder(\n    (patch_embed): PatchEmbed(\n      (proj): Conv3d(3, 768, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n    )\n    (blocks): ModuleList(\n      (0-11): 12 x Block(\n        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=768, out_features=768, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): Identity()\n        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n    (head): Identity()\n  )\n  (decoder): PretrainVisionTransformerDecoderMultiOutput(\n    (decoders): ModuleList(\n      (0-1): 2 x PretrainVisionTransformerDecoder(\n        (blocks): ModuleList(\n          (0-3): 4 x Block(\n            (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n            (attn): Attention(\n              (qkv): Linear(in_features=384, out_features=1152, bias=False)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=384, out_features=384, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path): Identity()\n            (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n              (act): GELU(approximate='none')\n              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n              (drop): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (head): Linear(in_features=384, out_features=1536, bias=True)\n      )\n    )\n  )\n  (encoder_to_decoder): Linear(in_features=768, out_features=384, bias=False)\n)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = run_videomae_vis_v2.get_model(args=args) \n",
    "\n",
    "checkpoint = torch.load(args.model_path, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval()\n",
    "\n",
    "# outputs = model(image_batch)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:59:02.874805200Z",
     "start_time": "2024-05-06T12:58:47.067380300Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs = model(image_batch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:59:03.276806300Z",
     "start_time": "2024-05-06T12:59:02.879806200Z"
    }
   },
   "outputs": [],
   "source": [
    "reload(run_videomae_vis_v2)\n",
    "\n",
    "\n",
    "\n",
    "rec_videos_patches = outputs[0]\n",
    "rec_densepose_patches = outputs[1]\n",
    "patch_size = model.encoder.patch_embed.patch_size\n",
    "unnorm_videos = run_videomae_vis_v2.unnormalize_frames(img=image_batch)\n",
    "_, rec_videos, _ = run_videomae_vis_v2.reconstruct_video_from_patches(\n",
    "    ori_img=unnorm_videos, patch_size=patch_size, bool_masked_pos=None, outputs=rec_videos_patches, frame_id_list=None)\n",
    "\n",
    "_, rec_densepose, _ = run_videomae_vis_v2.reconstruct_video_from_patches(\n",
    "    ori_img=unnorm_videos, patch_size=patch_size, bool_masked_pos=None, \n",
    "    outputs=rec_densepose_patches, frame_id_list=None,normalize_with_orig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 16, 224, 224])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_densepose[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T12:59:03.290804800Z",
     "start_time": "2024-05-06T12:59:03.272811900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# a = (torch.nn.functional.normalize(rec_densepose[0],dim=0) + torch.Tensor([1,1,1])[:,None,None,None]) / torch.Tensor([2,2,2])[:,None,None,None]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T12:59:03.332804800Z",
     "start_time": "2024-05-06T12:59:03.288806100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# print(f'mean: {a.mean(dim=[1,2,3])}')\n",
    "# print(f'std: {a.std(dim=[1,2,3])}')\n",
    "# print(f'min: {a.reshape(3, -1).min(dim=1)[0]}')\n",
    "# print(f'max: {a.reshape(3, -1).max(dim=1)[0] }')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T12:59:03.334803700Z",
     "start_time": "2024-05-06T12:59:03.303807100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:59:03.372806900Z",
     "start_time": "2024-05-06T12:59:03.321804900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([-1.6935e-05, -6.8499e-05,  3.8860e-05], grad_fn=<MeanBackward1>)\n",
      "std: tensor([0.1546, 0.1683, 0.1660], grad_fn=<StdBackward0>)\n",
      "min: tensor([-2.4869, -2.4794, -1.7007], grad_fn=<MinBackward0>)\n",
      "max: tensor([7.5820, 7.5551, 5.9062], grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f'mean: {rec_densepose[0].mean(dim=[1,2,3])}')\n",
    "print(f'std: {rec_densepose[0].std(dim=[1,2,3])}')\n",
    "print(f'min: {rec_densepose[0].reshape(3, -1).min(dim=1)[0]}')\n",
    "print(f'max: {rec_densepose[0].reshape(3, -1).max(dim=1)[0] }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:59:05.262844500Z",
     "start_time": "2024-05-06T12:59:03.371809Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "vids = d[0]\n",
    "labels = d[1]\n",
    "label_txt = d[3]['label_txt']\n",
    "fnames = d[3]['filenames']\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=0)\n",
    "\n",
    "for ori_vid,rec_vid,rec_dense,labels,txt_label, fname in zip(vids,rec_videos,rec_densepose,labels, label_txt, fnames):\n",
    "       \n",
    "    txt =  '\\n'.join([fname ,txt_label])\n",
    "\n",
    "    ori_vid = run_videomae_vis_v2.unnormalize_frames(ori_vid)\n",
    "    rec_dense = run_videomae_vis_v2.unnormalize_frames(rec_dense)\n",
    "    # rec_dense = (torch.nn.functional.normalize(rec_dense,dim=0) + torch.Tensor([1,1,1])[:,None,None,None]) / torch.Tensor([2,2,2])[:,None,None,None]\n",
    "    # rec_vid = run_videomae_vis_v2.unnormalize_frames(rec_vid)\n",
    "    # rec_dense = softmax(rec_dense)\n",
    "\n",
    "    save_folder = osp.join('videos',fname.replace('.mp4',''))\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    \n",
    "    run_videomae_vis_v2.save_video(ori_vid, osp.join(save_folder,'ori_vid_'+fname), txt=txt)\n",
    "\n",
    "    # run_videomae_vis_v2.save_video(ori_dense, osp.join(save_folder,'ori_dense_'+fname), txt=txt)\n",
    "\n",
    "    run_videomae_vis_v2.save_video(rec_vid, osp.join(save_folder,'rec_vid_'+fname), txt=txt)\n",
    "\n",
    "    run_videomae_vis_v2.save_video(rec_dense, osp.join(save_folder,'rec_dense_'+fname), txt=txt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:59:05.640871400Z",
     "start_time": "2024-05-06T12:59:05.266805Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T11:52:54.541167Z",
     "start_time": "2024-05-08T11:52:54.522161Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_class_weights(df,feature_names, alpha=10, beta=2):\n",
    "    class_weights = {}\n",
    "    positive_weights = {}\n",
    "    negative_weights = {}\n",
    "    class_frequency = {}\n",
    "    # N = len(df)\n",
    "    n_features = len(feature_names)\n",
    "\n",
    "    N = np.sum(df[feature_names].to_numpy())\n",
    "    for label in feature_names:\n",
    "        if label in df.columns:\n",
    "            positive_weights[label] = np.log((N+n_features) /(alpha * (sum(df[label] == 1))+1)*beta)\n",
    "            negative_weights[label] = np.log((N+n_features) /(alpha * (sum(df[label] == 0))+1)*beta)\n",
    "            \n",
    "        else:\n",
    "            positive_weights[label] = 0\n",
    "            negative_weights[label] = 0\n",
    "        \n",
    "        class_frequency[label] =  sum(df[label] == 1) / N\n",
    "\n",
    "            \n",
    "    # class_weights['positive_weights'] = pd.DataFrame.from_dict(positive_weights)\n",
    "    # class_weights['negative_weights'] = pd.DataFrame.from_dict(negative_weights)\n",
    "    class_weights = pd.DataFrame(zip(positive_weights.keys(),positive_weights.values(), negative_weights.values(),class_frequency.values()),columns=['class','positive_weights','negative_weights', 'class_frequency'])        \n",
    "    class_weights['method'] = 'inv'\n",
    "    return class_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "    class  positive_weights  negative_weights  class_frequency method\n0       1          3.015778         -1.075394         0.016313    inv\n1       2          2.834835         -1.072072         0.019576    inv\n2       3          1.546267         -1.017804         0.071370    inv\n3       4          4.479364         -1.088162         0.003670    inv\n4       5          0.133242         -0.744268         0.293638    inv\n5       6          3.652685         -1.083239         0.008564    inv\n6       7          2.094541         -1.049782         0.041191    inv\n7       8          1.194166         -0.984770         0.101550    inv\n8       9          0.127705         -0.741957         0.295269    inv\n9      10          4.285208         -1.087343         0.004486    inv\n10     11          4.050368         -1.086114         0.005710    inv\n11     12          1.592968         -1.021311         0.068108    inv\n12     13          2.991287         -1.074979         0.016721    inv\n13     14          2.564544         -1.065813         0.025693    inv\n14     15          4.285208         -1.087343         0.004486    inv\n15     16          3.751125         -1.084061         0.007749    inv\n16     17          3.040884         -1.075808         0.015905    inv",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>positive_weights</th>\n      <th>negative_weights</th>\n      <th>class_frequency</th>\n      <th>method</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3.015778</td>\n      <td>-1.075394</td>\n      <td>0.016313</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2.834835</td>\n      <td>-1.072072</td>\n      <td>0.019576</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1.546267</td>\n      <td>-1.017804</td>\n      <td>0.071370</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4.479364</td>\n      <td>-1.088162</td>\n      <td>0.003670</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.133242</td>\n      <td>-0.744268</td>\n      <td>0.293638</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>3.652685</td>\n      <td>-1.083239</td>\n      <td>0.008564</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>2.094541</td>\n      <td>-1.049782</td>\n      <td>0.041191</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>1.194166</td>\n      <td>-0.984770</td>\n      <td>0.101550</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>0.127705</td>\n      <td>-0.741957</td>\n      <td>0.295269</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>4.285208</td>\n      <td>-1.087343</td>\n      <td>0.004486</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>4.050368</td>\n      <td>-1.086114</td>\n      <td>0.005710</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>1.592968</td>\n      <td>-1.021311</td>\n      <td>0.068108</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>2.991287</td>\n      <td>-1.074979</td>\n      <td>0.016721</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>2.564544</td>\n      <td>-1.065813</td>\n      <td>0.025693</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>4.285208</td>\n      <td>-1.087343</td>\n      <td>0.004486</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16</td>\n      <td>3.751125</td>\n      <td>-1.084061</td>\n      <td>0.007749</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>3.040884</td>\n      <td>-1.075808</td>\n      <td>0.015905</td>\n      <td>inv</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train_one_hot_encoded\n",
    "feature_names = LABEL2ID.keys()\n",
    "\n",
    "class_weights =  get_class_weights(df,feature_names, alpha=3, beta=1)\n",
    "class_weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T11:52:55.135169800Z",
     "start_time": "2024-05-08T11:52:55.104160700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "array([15, 12, 12, ...,  9,  9,  9], dtype=int64)"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_raw['label'].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T11:53:11.856191200Z",
     "start_time": "2024-05-08T11:53:11.836184300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T11:53:15.728260600Z",
     "start_time": "2024-05-08T11:53:15.706254900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T11:53:16.298254100Z",
     "start_time": "2024-05-08T11:53:16.275268100Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# df = df_train_raw\n",
    "# labels = df['label'].values\n",
    "# classes = df['label'].unique()\n",
    "# class_weights_vals = compute_class_weight(class_weight=\"balanced\", classes=classes, y=labels)\n",
    "# # compute_class_weight()\n",
    "# class_weights = pd.DataFrame(zip(classes, class_weights_vals), columns=['class', 'positive_weights'])\n",
    "# class_weights.sort_values(by='class', inplace=True)\n",
    "# class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "                   filenames folder_name  durations    view  \\\n0  Sample0001_color_0001.mp4       train         76  center   \n1  Sample0001_color_0002.mp4       train         52  center   \n2  Sample0001_color_0003.mp4       train         39  center   \n3  Sample0001_color_0004.mp4       train         36  center   \n4  Sample0001_color_0005.mp4       train         38  center   \n\n                                              labels  \\\n0  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n1  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n2  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...   \n3  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...   \n4  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...   \n\n                                            metadata  \n0  {'sample_id': '0001_0001', 'start_frame': 100,...  \n1  {'sample_id': '0001_0002', 'start_frame': 837,...  \n2  {'sample_id': '0001_0003', 'start_frame': 1710...  \n3  {'sample_id': '0001_0004', 'start_frame': 4849...  \n4  {'sample_id': '0001_0005', 'start_frame': 6330...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filenames</th>\n      <th>folder_name</th>\n      <th>durations</th>\n      <th>view</th>\n      <th>labels</th>\n      <th>metadata</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sample0001_color_0001.mp4</td>\n      <td>train</td>\n      <td>76</td>\n      <td>center</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>{'sample_id': '0001_0001', 'start_frame': 100,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sample0001_color_0002.mp4</td>\n      <td>train</td>\n      <td>52</td>\n      <td>center</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>{'sample_id': '0001_0002', 'start_frame': 837,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sample0001_color_0003.mp4</td>\n      <td>train</td>\n      <td>39</td>\n      <td>center</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n      <td>{'sample_id': '0001_0003', 'start_frame': 1710...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sample0001_color_0004.mp4</td>\n      <td>train</td>\n      <td>36</td>\n      <td>center</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, ...</td>\n      <td>{'sample_id': '0001_0004', 'start_frame': 4849...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sample0001_color_0005.mp4</td>\n      <td>train</td>\n      <td>38</td>\n      <td>center</td>\n      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, ...</td>\n      <td>{'sample_id': '0001_0005', 'start_frame': 6330...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-08T11:53:17.810320Z",
     "start_time": "2024-05-08T11:53:17.790312700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-08T11:53:32.968684400Z",
     "start_time": "2024-05-08T11:53:32.928692400Z"
    }
   },
   "outputs": [],
   "source": [
    "save_folder = r'D:\\Project-mpg microgesture\\human_micro_gesture_classifier\\scripts\\miga_smg\\videomae_vit_base_patch16_224_kinetic_400_densepose_dual_multi\\dataset'\n",
    "# save_folder = osp.join(*save_folder.split('/'))\n",
    "\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "df_train.to_csv(osp.join(save_folder, 'train.csv'))\n",
    "# df_test.to_csv(osp.join(save_folder, 'test.csv'))\n",
    "df_val.to_csv(osp.join(save_folder, 'val.csv'))\n",
    "class_weights.to_csv(osp.join(save_folder, 'weights.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T13:24:14.552613600Z",
     "start_time": "2024-05-06T13:24:14.531607400Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "wrapped_data = {'data': class_weights.to_dict(orient='records')}\n",
    "\n",
    "# Save wrapped data as JSON\n",
    "with open(osp.join(save_folder, 'weights.json'), 'w') as json_file:\n",
    "    json.dump(wrapped_data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-01T11:19:33.989694300Z"
    }
   },
   "outputs": [],
   "source": [
    "len(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-01T11:19:33.991694600Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
