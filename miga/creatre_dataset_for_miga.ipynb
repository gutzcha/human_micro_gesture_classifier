{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T10:32:09.458909300Z",
     "start_time": "2024-05-07T10:32:07.729908600Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import os.path as osp\n",
    "from glob import glob\n",
    "import sys\n",
    "from const import ID2LABELS_SMG as LABEL2ID\n",
    "# Add the parent directory to the Python path\n",
    "sys.path.insert(0, '..')\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T10:32:16.485773700Z",
     "start_time": "2024-05-07T10:32:16.458792400Z"
    }
   },
   "outputs": [],
   "source": [
    "path_to_root_folder = '\\Project-mpg microgesture\\smg\\smg_split_files'\n",
    "path_to_root_folder = osp.join(*path_to_root_folder.split('/'))\n",
    "\n",
    "train_data_path = osp.join(path_to_root_folder,'train.csv')\n",
    "val_data_path = osp.join(path_to_root_folder,'validation.csv')\n",
    "\n",
    "train_files_folder = osp.join(path_to_root_folder, 'train')\n",
    "val_files_folder = osp.join(path_to_root_folder, 'validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T10:32:39.049277700Z",
     "start_time": "2024-05-07T10:32:39.029281200Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_raw = pd.read_csv(train_data_path, index_col=0)\n",
    "df_val_raw = pd.read_csv(val_data_path, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T10:32:39.721424800Z",
     "start_time": "2024-05-07T10:32:39.685382200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   label  start_frame  end_frame  \\\n0     15          100        176   \n1     12          837        889   \n2     12         1710       1749   \n3      8         4849       4885   \n4      9         6330       6368   \n\n                                               paths    basename  durations  \n0  ..\\..\\smg\\smg_split_files\\train\\Sample0001_col...  Sample0001         76  \n1  ..\\..\\smg\\smg_split_files\\train\\Sample0001_col...  Sample0001         52  \n2  ..\\..\\smg\\smg_split_files\\train\\Sample0001_col...  Sample0001         39  \n3  ..\\..\\smg\\smg_split_files\\train\\Sample0001_col...  Sample0001         36  \n4  ..\\..\\smg\\smg_split_files\\train\\Sample0001_col...  Sample0001         38  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>start_frame</th>\n      <th>end_frame</th>\n      <th>paths</th>\n      <th>basename</th>\n      <th>durations</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>15</td>\n      <td>100</td>\n      <td>176</td>\n      <td>..\\..\\smg\\smg_split_files\\train\\Sample0001_col...</td>\n      <td>Sample0001</td>\n      <td>76</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>12</td>\n      <td>837</td>\n      <td>889</td>\n      <td>..\\..\\smg\\smg_split_files\\train\\Sample0001_col...</td>\n      <td>Sample0001</td>\n      <td>52</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>12</td>\n      <td>1710</td>\n      <td>1749</td>\n      <td>..\\..\\smg\\smg_split_files\\train\\Sample0001_col...</td>\n      <td>Sample0001</td>\n      <td>39</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8</td>\n      <td>4849</td>\n      <td>4885</td>\n      <td>..\\..\\smg\\smg_split_files\\train\\Sample0001_col...</td>\n      <td>Sample0001</td>\n      <td>36</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9</td>\n      <td>6330</td>\n      <td>6368</td>\n      <td>..\\..\\smg\\smg_split_files\\train\\Sample0001_col...</td>\n      <td>Sample0001</td>\n      <td>38</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['label', 'start_frame', 'end_frame', 'paths', 'basename', 'durations'], dtype='object')"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_raw.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T10:32:40.980422900Z",
     "start_time": "2024-05-07T10:32:40.968416200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T10:32:42.829707800Z",
     "start_time": "2024-05-07T10:32:42.806703900Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Structure of the final dataset: filename, labels\n",
    "# def get_video_list(files_folder):\n",
    "#     all_files = glob(osp.join(files_folder, '*.mp4'))\n",
    "#     base_names = [osp.basename(f) for f in all_files]\n",
    "#     sample_id = [int(osp.splitext(f)[0].split('-')[0]) for f in base_names]\n",
    "#     view = [(osp.splitext(f)[0].split('-video')[-1]) for f in base_names]\n",
    "#     df = pd.DataFrame(zip(all_files, base_names, sample_id, view), columns=['filenames', 'base_name', 'sample_id', 'view'])\n",
    "#     return df\n",
    "# df_train_files = get_video_list(files_folder=train_files_folder)\n",
    "# df_val_files = get_video_list(files_folder=val_files_folder)\n",
    "# # file_sample_ids.sort()\n",
    "# # file_sample_ids\n",
    "# # df_train_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def convert_df(df_in):\n",
    "        \n",
    "    df_out = pd.DataFrame()\n",
    "    \n",
    "    df_out['filenames'] = df_in['paths'].apply(lambda x: osp.basename(x))\n",
    "    df_out['folder_name'] = df_in['paths'].apply(lambda x: x.split('\\\\')[-2])\n",
    "    df_out['durations'] = df_in['durations']\n",
    "    \n",
    "    df_out['view'] = 'center'\n",
    "    metadata = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    metadata['sample_id'] = df_out['filenames'].apply(lambda x: x.split('.')[0].replace('Sample','').replace('color_',''))\n",
    "    metadata['start_frame'] = df_in['start_frame']\n",
    "    metadata['end_frame'] = df_in['end_frame']\n",
    "    metadata['label_txt'] = df_in['label'].apply(lambda x: LABEL2ID[x])\n",
    "    metadata['label']= df_in['label']\n",
    "    metadata['view'] =  df_out['view']\n",
    "    metadata['filenames'] = df_out['filenames']\n",
    "    metadata['durations'] = df_out['durations']\n",
    "    \n",
    "    \n",
    "    one_hot_encoded  = pd.get_dummies(df_in['label'], columns=LABEL2ID.keys())\n",
    "    new_columns = one_hot_encoded.columns.to_list()\n",
    "    one_hot_encoded = one_hot_encoded.astype(float)\n",
    "    # df_out['labels'] = one_hot_encoded.values.tolist()\n",
    "    df_out['labels'] = df_in['label'] - 1\n",
    "    df_out['metadata'] = metadata.to_dict(orient='records')\n",
    "    \n",
    "    return df_out, new_columns, one_hot_encoded\n",
    "\n",
    "df_train,new_columns, train_one_hot_encoded = convert_df(df_train_raw)\n",
    "df_val, _, val_one_hot_encoded = convert_df(df_val_raw)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T10:32:43.550958Z",
     "start_time": "2024-05-07T10:32:43.510956700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "                    filenames folder_name  durations    view  labels  \\\n0   Sample0001_color_0001.mp4       train         76  center      14   \n1   Sample0001_color_0002.mp4       train         52  center      11   \n2   Sample0001_color_0003.mp4       train         39  center      11   \n3   Sample0001_color_0004.mp4       train         36  center       7   \n4   Sample0001_color_0005.mp4       train         38  center       8   \n..                        ...         ...        ...     ...     ...   \n51  Sample0030_color_0052.mp4       train         88  center       8   \n52  Sample0030_color_0053.mp4       train         97  center       8   \n53  Sample0030_color_0054.mp4       train        125  center       8   \n54  Sample0030_color_0055.mp4       train         66  center       8   \n55  Sample0030_color_0056.mp4       train        119  center       8   \n\n                                             metadata  \n0   {'sample_id': '0001_0001', 'start_frame': 100,...  \n1   {'sample_id': '0001_0002', 'start_frame': 837,...  \n2   {'sample_id': '0001_0003', 'start_frame': 1710...  \n3   {'sample_id': '0001_0004', 'start_frame': 4849...  \n4   {'sample_id': '0001_0005', 'start_frame': 6330...  \n..                                                ...  \n51  {'sample_id': '0030_0052', 'start_frame': 1919...  \n52  {'sample_id': '0030_0053', 'start_frame': 1941...  \n53  {'sample_id': '0030_0054', 'start_frame': 1955...  \n54  {'sample_id': '0030_0055', 'start_frame': 1968...  \n55  {'sample_id': '0030_0056', 'start_frame': 1976...  \n\n[2452 rows x 6 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filenames</th>\n      <th>folder_name</th>\n      <th>durations</th>\n      <th>view</th>\n      <th>labels</th>\n      <th>metadata</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sample0001_color_0001.mp4</td>\n      <td>train</td>\n      <td>76</td>\n      <td>center</td>\n      <td>14</td>\n      <td>{'sample_id': '0001_0001', 'start_frame': 100,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sample0001_color_0002.mp4</td>\n      <td>train</td>\n      <td>52</td>\n      <td>center</td>\n      <td>11</td>\n      <td>{'sample_id': '0001_0002', 'start_frame': 837,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sample0001_color_0003.mp4</td>\n      <td>train</td>\n      <td>39</td>\n      <td>center</td>\n      <td>11</td>\n      <td>{'sample_id': '0001_0003', 'start_frame': 1710...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sample0001_color_0004.mp4</td>\n      <td>train</td>\n      <td>36</td>\n      <td>center</td>\n      <td>7</td>\n      <td>{'sample_id': '0001_0004', 'start_frame': 4849...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sample0001_color_0005.mp4</td>\n      <td>train</td>\n      <td>38</td>\n      <td>center</td>\n      <td>8</td>\n      <td>{'sample_id': '0001_0005', 'start_frame': 6330...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>Sample0030_color_0052.mp4</td>\n      <td>train</td>\n      <td>88</td>\n      <td>center</td>\n      <td>8</td>\n      <td>{'sample_id': '0030_0052', 'start_frame': 1919...</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>Sample0030_color_0053.mp4</td>\n      <td>train</td>\n      <td>97</td>\n      <td>center</td>\n      <td>8</td>\n      <td>{'sample_id': '0030_0053', 'start_frame': 1941...</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>Sample0030_color_0054.mp4</td>\n      <td>train</td>\n      <td>125</td>\n      <td>center</td>\n      <td>8</td>\n      <td>{'sample_id': '0030_0054', 'start_frame': 1955...</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>Sample0030_color_0055.mp4</td>\n      <td>train</td>\n      <td>66</td>\n      <td>center</td>\n      <td>8</td>\n      <td>{'sample_id': '0030_0055', 'start_frame': 1968...</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>Sample0030_color_0056.mp4</td>\n      <td>train</td>\n      <td>119</td>\n      <td>center</td>\n      <td>8</td>\n      <td>{'sample_id': '0030_0056', 'start_frame': 1976...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2452 rows Ã— 6 columns</p>\n</div>"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T10:32:44.592963500Z",
     "start_time": "2024-05-07T10:32:44.556003600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[<Axes: title={'center': 'labels'}>]], dtype=object)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_train.hist('labels', bins=17)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-07T10:32:46.754958600Z",
     "start_time": "2024-05-07T10:32:46.059957500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:58:33.717071200Z",
     "start_time": "2024-05-06T12:58:33.669071800Z"
    }
   },
   "outputs": [],
   "source": [
    "experiment_folder = r'D:\\Project-mpg microgesture\\human_micro_gesture_classifier\\scripts\\miga_smg'\n",
    "run_name = 'videomae_vit_base_patch16_224_kinetic_400_densepose_dual_resample'\n",
    "\n",
    "os.makedirs(osp.join(experiment_folder, run_name), exist_ok=True)\n",
    "os.makedirs(osp.join(experiment_folder, run_name,'dataset'), exist_ok=True)\n",
    "\n",
    "df_val.to_csv(osp.join(experiment_folder,'val.csv'))\n",
    "df_train.to_csv(osp.join(experiment_folder,'train.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T10:36:07.100295500Z",
     "start_time": "2024-05-07T10:36:05.351880900Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Project-mpg microgesture\\human_micro_gesture_classifier\\miga\\..\\modeling_finetune.py:306: UserWarning: Overwriting vit_small_patch16_224 in registry with modeling_finetune.vit_small_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def vit_small_patch16_224(pretrained=False, **kwargs):\n",
      "D:\\Project-mpg microgesture\\human_micro_gesture_classifier\\miga\\..\\modeling_finetune.py:315: UserWarning: Overwriting vit_base_patch16_224 in registry with modeling_finetune.vit_base_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def vit_base_patch16_224(pretrained=False, **kwargs):\n",
      "D:\\Project-mpg microgesture\\human_micro_gesture_classifier\\miga\\..\\modeling_finetune.py:324: UserWarning: Overwriting vit_base_patch16_384 in registry with modeling_finetune.vit_base_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def vit_base_patch16_384(pretrained=False, **kwargs):\n",
      "D:\\Project-mpg microgesture\\human_micro_gesture_classifier\\miga\\..\\modeling_finetune.py:333: UserWarning: Overwriting vit_large_patch16_224 in registry with modeling_finetune.vit_large_patch16_224. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def vit_large_patch16_224(pretrained=False, **kwargs):\n",
      "D:\\Project-mpg microgesture\\human_micro_gesture_classifier\\miga\\..\\modeling_finetune.py:342: UserWarning: Overwriting vit_large_patch16_384 in registry with modeling_finetune.vit_large_patch16_384. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  def vit_large_patch16_384(pretrained=False, **kwargs):\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import dyadic_communication\n",
    "from importlib import reload\n",
    "import debug_model\n",
    "import run_videomae_vis_v2\n",
    "\n",
    "reload(dyadic_communication)\n",
    "reload(debug_model)\n",
    "reload(run_videomae_vis_v2)\n",
    "\n",
    "from argparse import Namespace\n",
    "import mpigroup.const as const\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T10:36:33.174771600Z",
     "start_time": "2024-05-07T10:36:33.142790600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'front1': 'tr', 'front2': 'tl', 'right': 'bl', 'left': 'br', 'center': 'mm'}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(const)\n",
    "cropping_map = const.cropping_map\n",
    "cropping_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-07T10:36:35.275444600Z",
     "start_time": "2024-05-07T10:36:33.752450100Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\Project-mpg microgesture\\\\human_micro_gesture_classifier\\\\scripts\\\\miga_smg\\\\val.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[14], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m args\u001B[38;5;241m.\u001B[39mmode \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalidation\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m      8\u001B[0m args\u001B[38;5;241m.\u001B[39mtest_mode \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m----> 9\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mdyadic_communication\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mDyadicvideoClsDataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m          \u001B[49m\u001B[43manno_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43manno_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     11\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdata_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[43m            \u001B[49m\u001B[43mmode\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     13\u001B[0m \u001B[43m            \u001B[49m\u001B[43mclip_len\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnum_segment\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_frames\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     15\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtest_num_segment\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_num_segment\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtest_num_crop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_num_crop\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnum_crop\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtest_mode\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01melse\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m            \u001B[49m\u001B[43mkeep_aspect_ratio\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcrop_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minput_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     20\u001B[0m \u001B[43m            \u001B[49m\u001B[43mshort_side_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshort_side_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     21\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnew_height\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m224\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     22\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnew_width\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m224\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     23\u001B[0m \u001B[43m            \u001B[49m\u001B[43mview_crop_mapping\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcropping_map\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     24\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcorner_crop_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     25\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdata_root\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_root\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     26\u001B[0m \u001B[43m            \u001B[49m\u001B[43margs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Project-mpg microgesture\\human_micro_gesture_classifier\\miga\\..\\dyadic_communication.py:54\u001B[0m, in \u001B[0;36mDyadicvideoClsDataset.__init__\u001B[1;34m(self, anno_path, data_path, mode, clip_len, crop_size, short_side_size, new_height, new_width, keep_aspect_ratio, num_segment, num_crop, test_num_segment, test_num_crop, view_crop_mapping, corner_crop_size, data_root, limit_data, args, **kwargs)\u001B[0m\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUnable to import `decord` which is required to read videos.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     53\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39manno_path, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m---> 54\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43manno_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     56\u001B[0m     df \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39manno_path\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\micro\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[0;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m   1014\u001B[0m     dialect,\n\u001B[0;32m   1015\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[0;32m   1023\u001B[0m )\n\u001B[0;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\micro\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    617\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[0;32m    619\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[1;32m--> 620\u001B[0m parser \u001B[38;5;241m=\u001B[39m TextFileReader(filepath_or_buffer, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwds)\n\u001B[0;32m    622\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[0;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\micro\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m   1617\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   1619\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m-> 1620\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\micro\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[1;34m(self, f, engine)\u001B[0m\n\u001B[0;32m   1878\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[0;32m   1879\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m-> 1880\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1881\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1882\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1883\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1884\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1885\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1886\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1887\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1888\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1889\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1890\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1891\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\micro\\lib\\site-packages\\pandas\\io\\common.py:873\u001B[0m, in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    868\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m    869\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[0;32m    870\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[0;32m    871\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[0;32m    872\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[1;32m--> 873\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m    874\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    875\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    876\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    877\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    878\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    879\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    880\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    881\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[0;32m    882\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'D:\\\\Project-mpg microgesture\\\\human_micro_gesture_classifier\\\\scripts\\\\miga_smg\\\\val.csv'"
     ]
    }
   ],
   "source": [
    "data_path= r'D:\\Project-mpg microgesture\\smg\\smg_split_files'\n",
    "\n",
    "args = debug_model.args\n",
    "args.anno_path = osp.join(experiment_folder,'val.csv')\n",
    "args.data_path = data_path\n",
    "args.data_root = data_path\n",
    "args.mode = 'validation'\n",
    "args.test_mode = False\n",
    "dataset = dyadic_communication.DyadicvideoClsDataset(\n",
    "          anno_path=args.anno_path,\n",
    "            data_path=args.data_path,\n",
    "            mode=args.mode,\n",
    "            clip_len=1,\n",
    "            num_segment=args.num_frames,\n",
    "            test_num_segment=args.test_num_segment,\n",
    "            test_num_crop=args.test_num_crop,\n",
    "            num_crop=1 if not args.test_mode else 3,\n",
    "            keep_aspect_ratio=True,\n",
    "            crop_size=args.input_size,\n",
    "            short_side_size=args.short_side_size,\n",
    "            new_height=224,\n",
    "            new_width=224,\n",
    "            view_crop_mapping=cropping_map,\n",
    "            corner_crop_size=None,\n",
    "            data_root=args.data_root,\n",
    "            args=args)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T12:58:36.008172700Z",
     "start_time": "2024-05-06T12:58:35.994171300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:58:37.324251600Z",
     "start_time": "2024-05-06T12:58:37.317251500Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "data = DataLoader(dataset=dataset, batch_size=5, shuffle=True)\n",
    "iterdata = iter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:58:40.858344500Z",
     "start_time": "2024-05-06T12:58:37.814344100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 16, 224, 224])\n",
      "tensor([6, 6, 6, 6, 2])\n",
      "[('D:\\\\Project-mpg microgesture\\\\smg\\\\smg_split_files\\\\validation\\\\Sample0033_color_0082', 'D:\\\\Project-mpg microgesture\\\\smg\\\\smg_split_files\\\\validation\\\\Sample0031_color_0044', 'D:\\\\Project-mpg microgesture\\\\smg\\\\smg_split_files\\\\validation\\\\Sample0033_color_0159', 'D:\\\\Project-mpg microgesture\\\\smg\\\\smg_split_files\\\\validation\\\\Sample0033_color_0005', 'D:\\\\Project-mpg microgesture\\\\smg\\\\smg_split_files\\\\validation\\\\Sample0033_color_0113'), {'sample_id': ['0033_0082', '0031_0044', '0033_0159', '0033_0005', '0033_0113'], 'start_frame': tensor([ 6978, 11895, 12230,   766,  8978]), 'end_frame': tensor([ 7023, 12078, 12316,   776,  9020]), 'label_txt': ['Arms akimbo', 'Arms akimbo', 'Arms akimbo', 'Arms akimbo', 'Moving legs'], 'view': ['center', 'center', 'center', 'center', 'center'], 'filenames': ['Sample0033_color_0082.mp4', 'Sample0031_color_0044.mp4', 'Sample0033_color_0159.mp4', 'Sample0033_color_0005.mp4', 'Sample0033_color_0113.mp4'], 'durations': tensor([ 45, 183,  86,  10,  42])}, [], []]\n"
     ]
    }
   ],
   "source": [
    "d = next(iterdata)\n",
    "print(d[0].shape)\n",
    "print(d[1])\n",
    "print(d[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:58:42.529344700Z",
     "start_time": "2024-05-06T12:58:40.842352800Z"
    }
   },
   "outputs": [],
   "source": [
    "reload(run_videomae_vis_v2)\n",
    "\n",
    "vids = d[0]\n",
    "labels = d[1]\n",
    "label_txt = d[3]['label_txt']\n",
    "fnames = d[3]['filenames']\n",
    "\n",
    "for vid,label, txt_label, fname in zip(vids,labels, label_txt, fnames):\n",
    "       \n",
    "    # ret = get_activities(feature_names, label)\n",
    "\n",
    "    txt =  '\\n'.join([fname ,txt_label])\n",
    "    \n",
    "    vid = run_videomae_vis_v2.unnormalize_frames(vid)\n",
    "    run_videomae_vis_v2.save_video(vid, osp.join('testing_'+fname), txt=txt)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:58:42.545355900Z",
     "start_time": "2024-05-06T12:58:42.530347600Z"
    }
   },
   "outputs": [],
   "source": [
    "# video_path = osp.join(path_to_root_folder,'clips_val','05942-video1.mp4')\n",
    "# video_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:58:42.571352400Z",
     "start_time": "2024-05-06T12:58:42.548346300Z"
    }
   },
   "outputs": [],
   "source": [
    "model_dict = {\n",
    "    'experiment':'MPIG_densepose_dual_2',\n",
    "    'description':'MPIG_densepose_dual - videoMAE-K400 , same as K400 but then was finetuned on MPIGroupInteractions dataset (train set) for 100 epochs, with denspose as additional decoding target',\n",
    "    'checkpoint_path':r'D:\\Project-mpg microgesture\\pretrained\\pretrained\\MPIIGroupInteraction\\k400_finetune_videomae_pretrain_dual_2_patch16_224_frame_16x4_tube_mask_ratio_0.9_e100\\checkpoint-99.pth',\n",
    "    'model_name':'pretrain_videomae_base_patch16_224_densepose_dual',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:58:42.580344200Z",
     "start_time": "2024-05-06T12:58:42.566348700Z"
    }
   },
   "outputs": [],
   "source": [
    "image_batch = d[0]\n",
    "save_folder = osp.join('videos')\n",
    "model_path = model_dict['checkpoint_path']\n",
    "model_name = model_dict['model_name']\n",
    "\n",
    "args = Namespace(\n",
    "        image_batch=image_batch,\n",
    "        save_path=save_folder, # list\n",
    "        model_path=model_path, \n",
    "        mask_type='tube',\n",
    "        num_frames=16,\n",
    "        sampling_rate=4,\n",
    "        decoder_depth=4,\n",
    "        input_size=224,\n",
    "        device='cuda:0',\n",
    "        imagenet_default_mean_and_std=True,\n",
    "        mask_ratio=0,\n",
    "        model=model_name,\n",
    "        densepose=True,\n",
    "        drop_path=0.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:58:47.064376800Z",
     "start_time": "2024-05-06T12:58:42.581345100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating model: pretrain_videomae_base_patch16_224_densepose_dual\n"
     ]
    },
    {
     "data": {
      "text/plain": "PretrainVisionTransformerMultiOutout(\n  (encoder): PretrainVisionTransformerEncoder(\n    (patch_embed): PatchEmbed(\n      (proj): Conv3d(3, 768, kernel_size=(2, 16, 16), stride=(2, 16, 16))\n    )\n    (blocks): ModuleList(\n      (0-11): 12 x Block(\n        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (attn): Attention(\n          (qkv): Linear(in_features=768, out_features=2304, bias=False)\n          (attn_drop): Dropout(p=0.0, inplace=False)\n          (proj): Linear(in_features=768, out_features=768, bias=True)\n          (proj_drop): Dropout(p=0.0, inplace=False)\n        )\n        (drop_path): Identity()\n        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n        (mlp): Mlp(\n          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n          (act): GELU(approximate='none')\n          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n          (drop): Dropout(p=0.0, inplace=False)\n        )\n      )\n    )\n    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n    (head): Identity()\n  )\n  (decoder): PretrainVisionTransformerDecoderMultiOutput(\n    (decoders): ModuleList(\n      (0-1): 2 x PretrainVisionTransformerDecoder(\n        (blocks): ModuleList(\n          (0-3): 4 x Block(\n            (norm1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n            (attn): Attention(\n              (qkv): Linear(in_features=384, out_features=1152, bias=False)\n              (attn_drop): Dropout(p=0.0, inplace=False)\n              (proj): Linear(in_features=384, out_features=384, bias=True)\n              (proj_drop): Dropout(p=0.0, inplace=False)\n            )\n            (drop_path): Identity()\n            (norm2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n            (mlp): Mlp(\n              (fc1): Linear(in_features=384, out_features=1536, bias=True)\n              (act): GELU(approximate='none')\n              (fc2): Linear(in_features=1536, out_features=384, bias=True)\n              (drop): Dropout(p=0.0, inplace=False)\n            )\n          )\n        )\n        (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n        (head): Linear(in_features=384, out_features=1536, bias=True)\n      )\n    )\n  )\n  (encoder_to_decoder): Linear(in_features=768, out_features=384, bias=False)\n)"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = run_videomae_vis_v2.get_model(args=args) \n",
    "\n",
    "checkpoint = torch.load(args.model_path, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.eval()\n",
    "\n",
    "# outputs = model(image_batch)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:59:02.874805200Z",
     "start_time": "2024-05-06T12:58:47.067380300Z"
    }
   },
   "outputs": [],
   "source": [
    "outputs = model(image_batch) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:59:03.276806300Z",
     "start_time": "2024-05-06T12:59:02.879806200Z"
    }
   },
   "outputs": [],
   "source": [
    "reload(run_videomae_vis_v2)\n",
    "\n",
    "\n",
    "\n",
    "rec_videos_patches = outputs[0]\n",
    "rec_densepose_patches = outputs[1]\n",
    "patch_size = model.encoder.patch_embed.patch_size\n",
    "unnorm_videos = run_videomae_vis_v2.unnormalize_frames(img=image_batch)\n",
    "_, rec_videos, _ = run_videomae_vis_v2.reconstruct_video_from_patches(\n",
    "    ori_img=unnorm_videos, patch_size=patch_size, bool_masked_pos=None, outputs=rec_videos_patches, frame_id_list=None)\n",
    "\n",
    "_, rec_densepose, _ = run_videomae_vis_v2.reconstruct_video_from_patches(\n",
    "    ori_img=unnorm_videos, patch_size=patch_size, bool_masked_pos=None, \n",
    "    outputs=rec_densepose_patches, frame_id_list=None,normalize_with_orig=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 16, 224, 224])"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_densepose[0].shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T12:59:03.290804800Z",
     "start_time": "2024-05-06T12:59:03.272811900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# a = (torch.nn.functional.normalize(rec_densepose[0],dim=0) + torch.Tensor([1,1,1])[:,None,None,None]) / torch.Tensor([2,2,2])[:,None,None,None]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T12:59:03.332804800Z",
     "start_time": "2024-05-06T12:59:03.288806100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "# print(f'mean: {a.mean(dim=[1,2,3])}')\n",
    "# print(f'std: {a.std(dim=[1,2,3])}')\n",
    "# print(f'min: {a.reshape(3, -1).min(dim=1)[0]}')\n",
    "# print(f'max: {a.reshape(3, -1).max(dim=1)[0] }')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T12:59:03.334803700Z",
     "start_time": "2024-05-06T12:59:03.303807100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:59:03.372806900Z",
     "start_time": "2024-05-06T12:59:03.321804900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([-1.6935e-05, -6.8499e-05,  3.8860e-05], grad_fn=<MeanBackward1>)\n",
      "std: tensor([0.1546, 0.1683, 0.1660], grad_fn=<StdBackward0>)\n",
      "min: tensor([-2.4869, -2.4794, -1.7007], grad_fn=<MinBackward0>)\n",
      "max: tensor([7.5820, 7.5551, 5.9062], grad_fn=<MaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f'mean: {rec_densepose[0].mean(dim=[1,2,3])}')\n",
    "print(f'std: {rec_densepose[0].std(dim=[1,2,3])}')\n",
    "print(f'min: {rec_densepose[0].reshape(3, -1).min(dim=1)[0]}')\n",
    "print(f'max: {rec_densepose[0].reshape(3, -1).max(dim=1)[0] }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:59:05.262844500Z",
     "start_time": "2024-05-06T12:59:03.371809Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "vids = d[0]\n",
    "labels = d[1]\n",
    "label_txt = d[3]['label_txt']\n",
    "fnames = d[3]['filenames']\n",
    "\n",
    "softmax = torch.nn.Softmax(dim=0)\n",
    "\n",
    "for ori_vid,rec_vid,rec_dense,labels,txt_label, fname in zip(vids,rec_videos,rec_densepose,labels, label_txt, fnames):\n",
    "       \n",
    "    txt =  '\\n'.join([fname ,txt_label])\n",
    "\n",
    "    ori_vid = run_videomae_vis_v2.unnormalize_frames(ori_vid)\n",
    "    rec_dense = run_videomae_vis_v2.unnormalize_frames(rec_dense)\n",
    "    # rec_dense = (torch.nn.functional.normalize(rec_dense,dim=0) + torch.Tensor([1,1,1])[:,None,None,None]) / torch.Tensor([2,2,2])[:,None,None,None]\n",
    "    # rec_vid = run_videomae_vis_v2.unnormalize_frames(rec_vid)\n",
    "    # rec_dense = softmax(rec_dense)\n",
    "\n",
    "    save_folder = osp.join('videos',fname.replace('.mp4',''))\n",
    "    os.makedirs(save_folder, exist_ok=True)\n",
    "    \n",
    "    run_videomae_vis_v2.save_video(ori_vid, osp.join(save_folder,'ori_vid_'+fname), txt=txt)\n",
    "\n",
    "    # run_videomae_vis_v2.save_video(ori_dense, osp.join(save_folder,'ori_dense_'+fname), txt=txt)\n",
    "\n",
    "    run_videomae_vis_v2.save_video(rec_vid, osp.join(save_folder,'rec_vid_'+fname), txt=txt)\n",
    "\n",
    "    run_videomae_vis_v2.save_video(rec_dense, osp.join(save_folder,'rec_dense_'+fname), txt=txt)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T12:59:05.640871400Z",
     "start_time": "2024-05-06T12:59:05.266805Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T20:38:02.733097700Z",
     "start_time": "2024-05-06T20:38:02.712127300Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_class_weights(df,feature_names, alpha=10, beta=2):\n",
    "    class_weights = {}\n",
    "    positive_weights = {}\n",
    "    negative_weights = {}\n",
    "    class_frequency = {}\n",
    "    # N = len(df)\n",
    "    n_features = len(feature_names)\n",
    "\n",
    "    N = np.sum(df[feature_names].to_numpy())\n",
    "    for label in feature_names:\n",
    "        if label in df.columns:\n",
    "            positive_weights[label] = np.log((N+n_features) /(alpha * (sum(df[label] == 1))+1)*beta)\n",
    "            negative_weights[label] = np.log((N+n_features) /(alpha * (sum(df[label] == 0))+1)*beta)\n",
    "            \n",
    "        else:\n",
    "            positive_weights[label] = 0\n",
    "            negative_weights[label] = 0\n",
    "        \n",
    "        class_frequency[label] =  sum(df[label] == 1) / N\n",
    "\n",
    "            \n",
    "    # class_weights['positive_weights'] = pd.DataFrame.from_dict(positive_weights)\n",
    "    # class_weights['negative_weights'] = pd.DataFrame.from_dict(negative_weights)\n",
    "    class_weights = pd.DataFrame(zip(positive_weights.keys(),positive_weights.values(), negative_weights.values(),class_frequency.values()),columns=['class','positive_weights','negative_weights', 'class_frequency'])        \n",
    "    class_weights['method'] = 'inv'\n",
    "    return class_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "    class  positive_weights  negative_weights  class_frequency method\n0       1          3.015778         -1.075394         0.016313    inv\n1       2          2.834835         -1.072072         0.019576    inv\n2       3          1.546267         -1.017804         0.071370    inv\n3       4          4.479364         -1.088162         0.003670    inv\n4       5          0.133242         -0.744268         0.293638    inv\n5       6          3.652685         -1.083239         0.008564    inv\n6       7          2.094541         -1.049782         0.041191    inv\n7       8          1.194166         -0.984770         0.101550    inv\n8       9          0.127705         -0.741957         0.295269    inv\n9      10          4.285208         -1.087343         0.004486    inv\n10     11          4.050368         -1.086114         0.005710    inv\n11     12          1.592968         -1.021311         0.068108    inv\n12     13          2.991287         -1.074979         0.016721    inv\n13     14          2.564544         -1.065813         0.025693    inv\n14     15          4.285208         -1.087343         0.004486    inv\n15     16          3.751125         -1.084061         0.007749    inv\n16     17          3.040884         -1.075808         0.015905    inv",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>positive_weights</th>\n      <th>negative_weights</th>\n      <th>class_frequency</th>\n      <th>method</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>3.015778</td>\n      <td>-1.075394</td>\n      <td>0.016313</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>2.834835</td>\n      <td>-1.072072</td>\n      <td>0.019576</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1.546267</td>\n      <td>-1.017804</td>\n      <td>0.071370</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>4.479364</td>\n      <td>-1.088162</td>\n      <td>0.003670</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.133242</td>\n      <td>-0.744268</td>\n      <td>0.293638</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>6</td>\n      <td>3.652685</td>\n      <td>-1.083239</td>\n      <td>0.008564</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>7</td>\n      <td>2.094541</td>\n      <td>-1.049782</td>\n      <td>0.041191</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>8</td>\n      <td>1.194166</td>\n      <td>-0.984770</td>\n      <td>0.101550</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>9</td>\n      <td>0.127705</td>\n      <td>-0.741957</td>\n      <td>0.295269</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>10</td>\n      <td>4.285208</td>\n      <td>-1.087343</td>\n      <td>0.004486</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>11</td>\n      <td>4.050368</td>\n      <td>-1.086114</td>\n      <td>0.005710</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>12</td>\n      <td>1.592968</td>\n      <td>-1.021311</td>\n      <td>0.068108</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>13</td>\n      <td>2.991287</td>\n      <td>-1.074979</td>\n      <td>0.016721</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>14</td>\n      <td>2.564544</td>\n      <td>-1.065813</td>\n      <td>0.025693</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>15</td>\n      <td>4.285208</td>\n      <td>-1.087343</td>\n      <td>0.004486</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>16</td>\n      <td>3.751125</td>\n      <td>-1.084061</td>\n      <td>0.007749</td>\n      <td>inv</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>17</td>\n      <td>3.040884</td>\n      <td>-1.075808</td>\n      <td>0.015905</td>\n      <td>inv</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train_one_hot_encoded\n",
    "feature_names = LABEL2ID.keys()\n",
    "\n",
    "class_weights =  get_class_weights(df,feature_names, alpha=3, beta=1)\n",
    "class_weights"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T20:39:46.613477700Z",
     "start_time": "2024-05-06T20:39:46.578471100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "array([15, 12, 12, ...,  9,  9,  9], dtype=int64)"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_raw['label'].values"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T13:22:50.203833100Z",
     "start_time": "2024-05-06T13:22:50.189175600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T13:17:42.976204400Z",
     "start_time": "2024-05-06T13:17:42.950610500Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# df = df_train_raw\n",
    "# labels = df['label'].values\n",
    "# classes = df['label'].unique()\n",
    "# class_weights_vals = compute_class_weight(class_weight=\"balanced\", classes=classes, y=labels)\n",
    "# # compute_class_weight()\n",
    "# class_weights = pd.DataFrame(zip(classes, class_weights_vals), columns=['class', 'positive_weights'])\n",
    "# class_weights.sort_values(by='class', inplace=True)\n",
    "# class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "data": {
      "text/plain": "                   filenames folder_name  durations    view  labels  \\\n0  Sample0001_color_0001.mp4       train         76  center      14   \n1  Sample0001_color_0002.mp4       train         52  center      11   \n2  Sample0001_color_0003.mp4       train         39  center      11   \n3  Sample0001_color_0004.mp4       train         36  center       7   \n4  Sample0001_color_0005.mp4       train         38  center       8   \n\n                                            metadata  \n0  {'sample_id': '0001_0001', 'start_frame': 100,...  \n1  {'sample_id': '0001_0002', 'start_frame': 837,...  \n2  {'sample_id': '0001_0003', 'start_frame': 1710...  \n3  {'sample_id': '0001_0004', 'start_frame': 4849...  \n4  {'sample_id': '0001_0005', 'start_frame': 6330...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filenames</th>\n      <th>folder_name</th>\n      <th>durations</th>\n      <th>view</th>\n      <th>labels</th>\n      <th>metadata</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Sample0001_color_0001.mp4</td>\n      <td>train</td>\n      <td>76</td>\n      <td>center</td>\n      <td>14</td>\n      <td>{'sample_id': '0001_0001', 'start_frame': 100,...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Sample0001_color_0002.mp4</td>\n      <td>train</td>\n      <td>52</td>\n      <td>center</td>\n      <td>11</td>\n      <td>{'sample_id': '0001_0002', 'start_frame': 837,...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Sample0001_color_0003.mp4</td>\n      <td>train</td>\n      <td>39</td>\n      <td>center</td>\n      <td>11</td>\n      <td>{'sample_id': '0001_0003', 'start_frame': 1710...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Sample0001_color_0004.mp4</td>\n      <td>train</td>\n      <td>36</td>\n      <td>center</td>\n      <td>7</td>\n      <td>{'sample_id': '0001_0004', 'start_frame': 4849...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Sample0001_color_0005.mp4</td>\n      <td>train</td>\n      <td>38</td>\n      <td>center</td>\n      <td>8</td>\n      <td>{'sample_id': '0001_0005', 'start_frame': 6330...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T21:35:06.369869700Z",
     "start_time": "2024-05-06T21:35:06.345760200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "outputs": [
    {
     "data": {
      "text/plain": "'D:\\\\Project-mpg microgesture\\\\human_micro_gesture_classifier\\\\scripts\\\\miga_smg\\\\videomae_vit_base_patch16_224_kinetic_400_densepose_dual\\\\dataset'"
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_folder"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T20:47:38.530648700Z",
     "start_time": "2024-05-06T20:47:38.494651100Z"
    }
   },
   "outputs": [],
   "source": [
    "save_folder = r'D:\\Project-mpg microgesture\\human_micro_gesture_classifier\\scripts\\miga_smg\\overfit_videomae_vit_base_patch16_224_kinetic_400_densepose_dual\\dataset'\n",
    "# save_folder = osp.join(*save_folder.split('/'))\n",
    "\n",
    "os.makedirs(save_folder, exist_ok=True)\n",
    "\n",
    "df_train.to_csv(osp.join(save_folder, 'train.csv'))\n",
    "# df_test.to_csv(osp.join(save_folder, 'test.csv'))\n",
    "df_val.to_csv(osp.join(save_folder, 'val.csv'))\n",
    "class_weights.to_csv(osp.join(save_folder, 'weights.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T13:24:14.552613600Z",
     "start_time": "2024-05-06T13:24:14.531607400Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "wrapped_data = {'data': class_weights.to_dict(orient='records')}\n",
    "\n",
    "# Save wrapped data as JSON\n",
    "with open(osp.join(save_folder, 'weights.json'), 'w') as json_file:\n",
    "    json.dump(wrapped_data, json_file, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-01T11:19:33.989694300Z"
    }
   },
   "outputs": [],
   "source": [
    "len(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-05-01T11:19:33.991694600Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
