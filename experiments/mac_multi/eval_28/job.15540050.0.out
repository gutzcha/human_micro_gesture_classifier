Not using distributed mode
Namespace(multi_labels=True, one_hot_labels=False, pos_weight_path='/lustre/fast/fast/ygoussha/mac2024_experiments/dataset/weights.json', limit_data=None, batch_size=2, epochs=300, update_freq=1, save_ckpt_freq=10, model='vit_base_patch16_224', tubelet_size=2, input_size=224, fc_drop_rate=0.0, drop=0.0, attn_drop_rate=0.0, drop_path=0.1, disable_eval_during_finetuning=False, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, opt='adamw', opt_eps=1e-08, opt_betas=[0.9, 0.999], clip_grad=None, momentum=0.9, weight_decay=0.05, weight_decay_end=None, lr=0.0005, layer_decay=0.75, warmup_lr=1e-06, min_lr=1e-06, warmup_epochs=5, warmup_steps=-1, color_jitter=0.4, num_sample=1, aa='rand-m7-n4-mstd0.5-inc1', smoothing=0.0, train_interpolation='bicubic', crop_pct=None, short_side_size=224, test_num_segment=1, test_num_crop=1, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.0, cutmix=0.0, cutmix_minmax=None, mixup_prob=0.0, mixup_switch_prob=0.5, mixup_mode='batch', finetune='/lustre/fast/fast/ygoussha/mac2024_experiments/checkpoint-best.pth', model_key='model|module', model_prefix='', init_scale=0.001, use_checkpoint=False, use_mean_pooling=True, data_path='/lustre/fast/fast/ygoussha/mac2024_experiments/dataset', eval_data_path=None, nb_classes=56, imagenet_default_mean_and_std=True, num_segments=1, num_frames=16, sampling_rate=4, data_set='dyadic_communication_mpigroup', output_dir='/lustre/fast/fast/ygoussha/mac2024_experiments/eval_28', data_root='/lustre/fast/fast/ygoussha/mac2024/track1', log_dir='/lustre/fast/fast/ygoussha/mac2024_experiments/eval_28', device='cuda', seed=0, resume='', auto_resume=True, save_ckpt=True, start_epoch=0, eval=True, dist_eval=True, num_workers=10, pin_mem=True, world_size=1, local_rank=-1, dist_on_itp=False, dist_url='env://', enable_deepspeed=False, distributed=False)
Number of the class = 56
Number of the class = 56
No test datset, trying to use val as test
Number of the class = 56
Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x14c501b02410>
Patch size = (16, 16)
Load ckpt from /lustre/fast/fast/ygoussha/mac2024_experiments/checkpoint-best.pth
Load state_dict by model_key = model
Model = VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv3d(3, 768, kernel_size=(2, 16, 16), stride=(2, 16, 16))
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (blocks): ModuleList(
    (0): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (1): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.00909090880304575)
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (2): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.0181818176060915)
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (3): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.027272727340459824)
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (4): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.036363635212183)
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (5): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.045454543083906174)
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (6): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.054545458406209946)
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (7): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.06363636255264282)
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (8): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.0727272778749466)
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (9): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.08181818574666977)
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (10): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.09090909361839294)
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (11): Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.10000000149011612)
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): Identity()
  (fc_norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
  (fc_dropout): Identity()
  (head): Linear(in_features=768, out_features=56, bias=True)
)
number of params: 86270264
LR = 0.00000391
Batch size = 2
Update frequent = 1
Number of training examples = 11250
Number of training training per epoch = 5625
Assigned values = [0.023757264018058777, 0.03167635202407837, 0.04223513603210449, 0.056313514709472656, 0.07508468627929688, 0.1001129150390625, 0.13348388671875, 0.177978515625, 0.2373046875, 0.31640625, 0.421875, 0.5625, 0.75, 1.0]
Skip weight decay list:  {'pos_embed', 'cls_token'}
Param groups = {
  "layer_0_decay": {
    "weight_decay": 0.05,
    "params": [
      "patch_embed.proj.weight"
    ],
    "lr_scale": 0.023757264018058777
  },
  "layer_0_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "patch_embed.proj.bias"
    ],
    "lr_scale": 0.023757264018058777
  },
  "layer_1_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.0.norm1.weight",
      "blocks.0.norm1.bias",
      "blocks.0.attn.q_bias",
      "blocks.0.attn.v_bias",
      "blocks.0.attn.proj.bias",
      "blocks.0.norm2.weight",
      "blocks.0.norm2.bias",
      "blocks.0.mlp.fc1.bias",
      "blocks.0.mlp.fc2.bias"
    ],
    "lr_scale": 0.03167635202407837
  },
  "layer_1_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.0.attn.qkv.weight",
      "blocks.0.attn.proj.weight",
      "blocks.0.mlp.fc1.weight",
      "blocks.0.mlp.fc2.weight"
    ],
    "lr_scale": 0.03167635202407837
  },
  "layer_2_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.1.norm1.weight",
      "blocks.1.norm1.bias",
      "blocks.1.attn.q_bias",
      "blocks.1.attn.v_bias",
      "blocks.1.attn.proj.bias",
      "blocks.1.norm2.weight",
      "blocks.1.norm2.bias",
      "blocks.1.mlp.fc1.bias",
      "blocks.1.mlp.fc2.bias"
    ],
    "lr_scale": 0.04223513603210449
  },
  "layer_2_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.1.attn.qkv.weight",
      "blocks.1.attn.proj.weight",
      "blocks.1.mlp.fc1.weight",
      "blocks.1.mlp.fc2.weight"
    ],
    "lr_scale": 0.04223513603210449
  },
  "layer_3_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.2.norm1.weight",
      "blocks.2.norm1.bias",
      "blocks.2.attn.q_bias",
      "blocks.2.attn.v_bias",
      "blocks.2.attn.proj.bias",
      "blocks.2.norm2.weight",
      "blocks.2.norm2.bias",
      "blocks.2.mlp.fc1.bias",
      "blocks.2.mlp.fc2.bias"
    ],
    "lr_scale": 0.056313514709472656
  },
  "layer_3_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.2.attn.qkv.weight",
      "blocks.2.attn.proj.weight",
      "blocks.2.mlp.fc1.weight",
      "blocks.2.mlp.fc2.weight"
    ],
    "lr_scale": 0.056313514709472656
  },
  "layer_4_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.3.norm1.weight",
      "blocks.3.norm1.bias",
      "blocks.3.attn.q_bias",
      "blocks.3.attn.v_bias",
      "blocks.3.attn.proj.bias",
      "blocks.3.norm2.weight",
      "blocks.3.norm2.bias",
      "blocks.3.mlp.fc1.bias",
      "blocks.3.mlp.fc2.bias"
    ],
    "lr_scale": 0.07508468627929688
  },
  "layer_4_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.3.attn.qkv.weight",
      "blocks.3.attn.proj.weight",
      "blocks.3.mlp.fc1.weight",
      "blocks.3.mlp.fc2.weight"
    ],
    "lr_scale": 0.07508468627929688
  },
  "layer_5_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.4.norm1.weight",
      "blocks.4.norm1.bias",
      "blocks.4.attn.q_bias",
      "blocks.4.attn.v_bias",
      "blocks.4.attn.proj.bias",
      "blocks.4.norm2.weight",
      "blocks.4.norm2.bias",
      "blocks.4.mlp.fc1.bias",
      "blocks.4.mlp.fc2.bias"
    ],
    "lr_scale": 0.1001129150390625
  },
  "layer_5_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.4.attn.qkv.weight",
      "blocks.4.attn.proj.weight",
      "blocks.4.mlp.fc1.weight",
      "blocks.4.mlp.fc2.weight"
    ],
    "lr_scale": 0.1001129150390625
  },
  "layer_6_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.5.norm1.weight",
      "blocks.5.norm1.bias",
      "blocks.5.attn.q_bias",
      "blocks.5.attn.v_bias",
      "blocks.5.attn.proj.bias",
      "blocks.5.norm2.weight",
      "blocks.5.norm2.bias",
      "blocks.5.mlp.fc1.bias",
      "blocks.5.mlp.fc2.bias"
    ],
    "lr_scale": 0.13348388671875
  },
  "layer_6_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.5.attn.qkv.weight",
      "blocks.5.attn.proj.weight",
      "blocks.5.mlp.fc1.weight",
      "blocks.5.mlp.fc2.weight"
    ],
    "lr_scale": 0.13348388671875
  },
  "layer_7_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.6.norm1.weight",
      "blocks.6.norm1.bias",
      "blocks.6.attn.q_bias",
      "blocks.6.attn.v_bias",
      "blocks.6.attn.proj.bias",
      "blocks.6.norm2.weight",
      "blocks.6.norm2.bias",
      "blocks.6.mlp.fc1.bias",
      "blocks.6.mlp.fc2.bias"
    ],
    "lr_scale": 0.177978515625
  },
  "layer_7_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.6.attn.qkv.weight",
      "blocks.6.attn.proj.weight",
      "blocks.6.mlp.fc1.weight",
      "blocks.6.mlp.fc2.weight"
    ],
    "lr_scale": 0.177978515625
  },
  "layer_8_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.7.norm1.weight",
      "blocks.7.norm1.bias",
      "blocks.7.attn.q_bias",
      "blocks.7.attn.v_bias",
      "blocks.7.attn.proj.bias",
      "blocks.7.norm2.weight",
      "blocks.7.norm2.bias",
      "blocks.7.mlp.fc1.bias",
      "blocks.7.mlp.fc2.bias"
    ],
    "lr_scale": 0.2373046875
  },
  "layer_8_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.7.attn.qkv.weight",
      "blocks.7.attn.proj.weight",
      "blocks.7.mlp.fc1.weight",
      "blocks.7.mlp.fc2.weight"
    ],
    "lr_scale": 0.2373046875
  },
  "layer_9_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.8.norm1.weight",
      "blocks.8.norm1.bias",
      "blocks.8.attn.q_bias",
      "blocks.8.attn.v_bias",
      "blocks.8.attn.proj.bias",
      "blocks.8.norm2.weight",
      "blocks.8.norm2.bias",
      "blocks.8.mlp.fc1.bias",
      "blocks.8.mlp.fc2.bias"
    ],
    "lr_scale": 0.31640625
  },
  "layer_9_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.8.attn.qkv.weight",
      "blocks.8.attn.proj.weight",
      "blocks.8.mlp.fc1.weight",
      "blocks.8.mlp.fc2.weight"
    ],
    "lr_scale": 0.31640625
  },
  "layer_10_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.9.norm1.weight",
      "blocks.9.norm1.bias",
      "blocks.9.attn.q_bias",
      "blocks.9.attn.v_bias",
      "blocks.9.attn.proj.bias",
      "blocks.9.norm2.weight",
      "blocks.9.norm2.bias",
      "blocks.9.mlp.fc1.bias",
      "blocks.9.mlp.fc2.bias"
    ],
    "lr_scale": 0.421875
  },
  "layer_10_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.9.attn.qkv.weight",
      "blocks.9.attn.proj.weight",
      "blocks.9.mlp.fc1.weight",
      "blocks.9.mlp.fc2.weight"
    ],
    "lr_scale": 0.421875
  },
  "layer_11_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.10.norm1.weight",
      "blocks.10.norm1.bias",
      "blocks.10.attn.q_bias",
      "blocks.10.attn.v_bias",
      "blocks.10.attn.proj.bias",
      "blocks.10.norm2.weight",
      "blocks.10.norm2.bias",
      "blocks.10.mlp.fc1.bias",
      "blocks.10.mlp.fc2.bias"
    ],
    "lr_scale": 0.5625
  },
  "layer_11_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.10.attn.qkv.weight",
      "blocks.10.attn.proj.weight",
      "blocks.10.mlp.fc1.weight",
      "blocks.10.mlp.fc2.weight"
    ],
    "lr_scale": 0.5625
  },
  "layer_12_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.11.norm1.weight",
      "blocks.11.norm1.bias",
      "blocks.11.attn.q_bias",
      "blocks.11.attn.v_bias",
      "blocks.11.attn.proj.bias",
      "blocks.11.norm2.weight",
      "blocks.11.norm2.bias",
      "blocks.11.mlp.fc1.bias",
      "blocks.11.mlp.fc2.bias"
    ],
    "lr_scale": 0.75
  },
  "layer_12_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.11.attn.qkv.weight",
      "blocks.11.attn.proj.weight",
      "blocks.11.mlp.fc1.weight",
      "blocks.11.mlp.fc2.weight"
    ],
    "lr_scale": 0.75
  },
  "layer_13_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "fc_norm.weight",
      "fc_norm.bias",
      "head.bias"
    ],
    "lr_scale": 1.0
  },
  "layer_13_decay": {
    "weight_decay": 0.05,
    "params": [
      "head.weight"
    ],
    "lr_scale": 1.0
  }
}
optimizer settings: {'lr': 3.90625e-06, 'weight_decay': 0.0, 'eps': 1e-08, 'betas': [0.9, 0.999]}
Use step level LR scheduler!
Set warmup steps = 28125
Set warmup steps = 0
Max WD = 0.0500000, Min WD = 0.0500000
criterion = BCEWithLogitsLoss()
Auto resume checkpoint: 
Test:  [   0/2793]  eta: 4:23:20  loss: 0.0812 (0.0812)  acc1: 0.5000 (0.5000)  acc5: 1.0000 (1.0000)  time: 5.6571  data: 2.0760  max mem: 917
Test:  [  10/2793]  eta: 0:24:54  loss: 0.0623 (0.0680)  acc1: 0.5000 (0.5000)  acc5: 1.0000 (1.0000)  time: 0.5369  data: 0.1889  max mem: 917
Test:  [  20/2793]  eta: 0:13:43  loss: 0.0670 (0.0878)  acc1: 0.5000 (0.5000)  acc5: 1.0000 (0.9643)  time: 0.0288  data: 0.0002  max mem: 917
Test:  [  30/2793]  eta: 0:10:35  loss: 0.1410 (0.1198)  acc1: 0.5000 (0.4919)  acc5: 0.7500 (0.8952)  time: 0.0610  data: 0.0275  max mem: 917
Test:  [  40/2793]  eta: 0:09:12  loss: 0.1839 (0.1371)  acc1: 0.5000 (0.4573)  acc5: 0.5000 (0.8232)  time: 0.1000  data: 0.0660  max mem: 917
Test:  [  50/2793]  eta: 0:08:13  loss: 0.1258 (0.1273)  acc1: 0.5000 (0.4657)  acc5: 0.7500 (0.8480)  time: 0.1022  data: 0.0669  max mem: 917
Test:  [  60/2793]  eta: 0:07:32  loss: 0.0908 (0.1248)  acc1: 0.5000 (0.4549)  acc5: 1.0000 (0.8279)  time: 0.0928  data: 0.0560  max mem: 917
Test:  [  70/2793]  eta: 0:07:07  loss: 0.1445 (0.1401)  acc1: 0.2500 (0.4296)  acc5: 0.7500 (0.7993)  time: 0.0985  data: 0.0621  max mem: 917
Test:  [  80/2793]  eta: 0:06:50  loss: 0.1882 (0.1452)  acc1: 0.2500 (0.4165)  acc5: 0.6667 (0.7850)  time: 0.1078  data: 0.0736  max mem: 917
Test:  [  90/2793]  eta: 0:06:32  loss: 0.1689 (0.1466)  acc1: 0.3333 (0.4064)  acc5: 0.6667 (0.7674)  time: 0.1034  data: 0.0721  max mem: 917
Test:  [ 100/2793]  eta: 0:06:26  loss: 0.1826 (0.1545)  acc1: 0.5000 (0.4023)  acc5: 0.7500 (0.7587)  time: 0.1117  data: 0.0788  max mem: 917
Test:  [ 110/2793]  eta: 0:06:11  loss: 0.1719 (0.1529)  acc1: 0.4000 (0.3991)  acc5: 0.7500 (0.7557)  time: 0.1087  data: 0.0721  max mem: 917
Test:  [ 120/2793]  eta: 0:06:03  loss: 0.1319 (0.1519)  acc1: 0.5000 (0.3992)  acc5: 0.7500 (0.7594)  time: 0.0996  data: 0.0640  max mem: 917
Test:  [ 130/2793]  eta: 0:06:00  loss: 0.1490 (0.1559)  acc1: 0.5000 (0.3992)  acc5: 0.7500 (0.7567)  time: 0.1184  data: 0.0847  max mem: 917
Test:  [ 140/2793]  eta: 0:05:54  loss: 0.1713 (0.1567)  acc1: 0.5000 (0.4046)  acc5: 0.7500 (0.7563)  time: 0.1180  data: 0.0839  max mem: 917
Test:  [ 150/2793]  eta: 0:05:48  loss: 0.1455 (0.1563)  acc1: 0.5000 (0.4086)  acc5: 0.7500 (0.7608)  time: 0.1080  data: 0.0723  max mem: 917
Test:  [ 160/2793]  eta: 0:05:39  loss: 0.1380 (0.1551)  acc1: 0.3333 (0.4029)  acc5: 0.8333 (0.7664)  time: 0.0951  data: 0.0600  max mem: 917
Test:  [ 170/2793]  eta: 0:05:34  loss: 0.1194 (0.1542)  acc1: 0.3333 (0.4037)  acc5: 1.0000 (0.7722)  time: 0.0940  data: 0.0597  max mem: 917
Test:  [ 180/2793]  eta: 0:05:31  loss: 0.1061 (0.1511)  acc1: 0.5000 (0.4076)  acc5: 1.0000 (0.7793)  time: 0.1104  data: 0.0744  max mem: 917
Test:  [ 190/2793]  eta: 0:05:26  loss: 0.1061 (0.1517)  acc1: 0.5000 (0.4029)  acc5: 1.0000 (0.7821)  time: 0.1096  data: 0.0750  max mem: 917
Test:  [ 200/2793]  eta: 0:05:22  loss: 0.0741 (0.1473)  acc1: 0.5000 (0.4077)  acc5: 1.0000 (0.7930)  time: 0.1029  data: 0.0693  max mem: 917
Test:  [ 210/2793]  eta: 0:05:18  loss: 0.0582 (0.1431)  acc1: 0.5000 (0.4121)  acc5: 1.0000 (0.8028)  time: 0.1033  data: 0.0689  max mem: 917
Test:  [ 220/2793]  eta: 0:05:16  loss: 0.0589 (0.1409)  acc1: 0.5000 (0.4142)  acc5: 1.0000 (0.8072)  time: 0.1103  data: 0.0749  max mem: 917
Test:  [ 230/2793]  eta: 0:05:11  loss: 0.0652 (0.1390)  acc1: 0.5000 (0.4168)  acc5: 1.0000 (0.8123)  time: 0.1013  data: 0.0671  max mem: 917
Test:  [ 240/2793]  eta: 0:05:08  loss: 0.0953 (0.1384)  acc1: 0.5000 (0.4147)  acc5: 1.0000 (0.8128)  time: 0.0975  data: 0.0638  max mem: 917
Test:  [ 250/2793]  eta: 0:05:05  loss: 0.1150 (0.1393)  acc1: 0.2500 (0.4092)  acc5: 0.7500 (0.8083)  time: 0.1045  data: 0.0674  max mem: 917
Test:  [ 260/2793]  eta: 0:05:05  loss: 0.1270 (0.1398)  acc1: 0.5000 (0.4117)  acc5: 1.0000 (0.8118)  time: 0.1142  data: 0.0775  max mem: 917
Test:  [ 270/2793]  eta: 0:05:04  loss: 0.1270 (0.1423)  acc1: 0.5000 (0.4094)  acc5: 1.0000 (0.8114)  time: 0.1267  data: 0.0917  max mem: 917
Test:  [ 280/2793]  eta: 0:05:03  loss: 0.1628 (0.1438)  acc1: 0.5000 (0.4100)  acc5: 0.7500 (0.8110)  time: 0.1248  data: 0.0921  max mem: 917
Test:  [ 290/2793]  eta: 0:05:00  loss: 0.1819 (0.1462)  acc1: 0.5000 (0.4079)  acc5: 0.7500 (0.8106)  time: 0.1131  data: 0.0820  max mem: 917
Test:  [ 300/2793]  eta: 0:04:59  loss: 0.1553 (0.1464)  acc1: 0.3333 (0.4060)  acc5: 0.8333 (0.8091)  time: 0.1088  data: 0.0764  max mem: 917
Test:  [ 310/2793]  eta: 0:04:57  loss: 0.1624 (0.1485)  acc1: 0.3333 (0.4008)  acc5: 0.7500 (0.8054)  time: 0.1129  data: 0.0784  max mem: 917
Test:  [ 320/2793]  eta: 0:04:55  loss: 0.1277 (0.1478)  acc1: 0.3333 (0.3982)  acc5: 0.6667 (0.8068)  time: 0.1143  data: 0.0792  max mem: 917
Test:  [ 330/2793]  eta: 0:04:53  loss: 0.1384 (0.1495)  acc1: 0.3333 (0.3957)  acc5: 0.7500 (0.8043)  time: 0.1086  data: 0.0734  max mem: 917
Test:  [ 340/2793]  eta: 0:04:49  loss: 0.1361 (0.1492)  acc1: 0.4000 (0.3952)  acc5: 0.8333 (0.8028)  time: 0.0927  data: 0.0589  max mem: 917
Test:  [ 350/2793]  eta: 0:04:46  loss: 0.1021 (0.1499)  acc1: 0.5000 (0.3960)  acc5: 0.8333 (0.8020)  time: 0.0893  data: 0.0554  max mem: 917
Test:  [ 360/2793]  eta: 0:04:44  loss: 0.1019 (0.1506)  acc1: 0.5000 (0.3940)  acc5: 0.7500 (0.7985)  time: 0.0958  data: 0.0585  max mem: 917
Test:  [ 370/2793]  eta: 0:04:41  loss: 0.0709 (0.1489)  acc1: 0.5000 (0.3956)  acc5: 1.0000 (0.8026)  time: 0.0979  data: 0.0606  max mem: 917
Test:  [ 380/2793]  eta: 0:04:39  loss: 0.0709 (0.1472)  acc1: 0.5000 (0.3963)  acc5: 1.0000 (0.8058)  time: 0.0975  data: 0.0637  max mem: 917
Test:  [ 390/2793]  eta: 0:04:37  loss: 0.0845 (0.1468)  acc1: 0.5000 (0.3958)  acc5: 1.0000 (0.8044)  time: 0.0987  data: 0.0656  max mem: 917
Test:  [ 400/2793]  eta: 0:04:34  loss: 0.1458 (0.1476)  acc1: 0.2500 (0.3940)  acc5: 0.7500 (0.8024)  time: 0.0965  data: 0.0626  max mem: 917
Test:  [ 410/2793]  eta: 0:04:34  loss: 0.2149 (0.1509)  acc1: 0.3333 (0.3913)  acc5: 0.5000 (0.7981)  time: 0.1143  data: 0.0785  max mem: 917
Test:  [ 420/2793]  eta: 0:04:34  loss: 0.2590 (0.1523)  acc1: 0.2500 (0.3868)  acc5: 0.5000 (0.7946)  time: 0.1294  data: 0.0936  max mem: 917
Test:  [ 430/2793]  eta: 0:04:31  loss: 0.1787 (0.1527)  acc1: 0.2500 (0.3813)  acc5: 0.5000 (0.7860)  time: 0.1098  data: 0.0759  max mem: 917
Test:  [ 440/2793]  eta: 0:04:29  loss: 0.1397 (0.1523)  acc1: 0.2500 (0.3760)  acc5: 0.5000 (0.7812)  time: 0.0950  data: 0.0622  max mem: 917
Test:  [ 450/2793]  eta: 0:04:27  loss: 0.1291 (0.1525)  acc1: 0.2500 (0.3744)  acc5: 0.5000 (0.7783)  time: 0.0941  data: 0.0625  max mem: 917
Test:  [ 460/2793]  eta: 0:04:26  loss: 0.1264 (0.1521)  acc1: 0.2500 (0.3738)  acc5: 0.7500 (0.7799)  time: 0.1084  data: 0.0773  max mem: 917
Test:  [ 470/2793]  eta: 0:04:25  loss: 0.1260 (0.1518)  acc1: 0.2500 (0.3738)  acc5: 1.0000 (0.7819)  time: 0.1192  data: 0.0856  max mem: 917
Test:  [ 480/2793]  eta: 0:04:24  loss: 0.1524 (0.1525)  acc1: 0.3333 (0.3723)  acc5: 0.7500 (0.7794)  time: 0.1171  data: 0.0816  max mem: 917
Test:  [ 490/2793]  eta: 0:04:22  loss: 0.1226 (0.1518)  acc1: 0.3333 (0.3711)  acc5: 0.8333 (0.7819)  time: 0.1091  data: 0.0758  max mem: 917
Test:  [ 500/2793]  eta: 0:04:21  loss: 0.1024 (0.1513)  acc1: 0.3333 (0.3722)  acc5: 1.0000 (0.7837)  time: 0.1043  data: 0.0717  max mem: 917
Test:  [ 510/2793]  eta: 0:04:20  loss: 0.1105 (0.1511)  acc1: 0.5000 (0.3708)  acc5: 0.7500 (0.7811)  time: 0.1120  data: 0.0765  max mem: 917
Test:  [ 520/2793]  eta: 0:04:19  loss: 0.1719 (0.1529)  acc1: 0.2500 (0.3691)  acc5: 0.7500 (0.7788)  time: 0.1117  data: 0.0764  max mem: 917
Test:  [ 530/2793]  eta: 0:04:17  loss: 0.1417 (0.1521)  acc1: 0.3333 (0.3691)  acc5: 1.0000 (0.7829)  time: 0.1120  data: 0.0799  max mem: 917
Test:  [ 540/2793]  eta: 0:04:16  loss: 0.0901 (0.1517)  acc1: 0.3333 (0.3687)  acc5: 1.0000 (0.7823)  time: 0.1081  data: 0.0744  max mem: 917
Test:  [ 550/2793]  eta: 0:04:14  loss: 0.1433 (0.1515)  acc1: 0.5000 (0.3702)  acc5: 0.7500 (0.7835)  time: 0.1053  data: 0.0691  max mem: 917
Test:  [ 560/2793]  eta: 0:04:13  loss: 0.1546 (0.1524)  acc1: 0.5000 (0.3702)  acc5: 0.7500 (0.7817)  time: 0.1027  data: 0.0684  max mem: 917
Test:  [ 570/2793]  eta: 0:04:11  loss: 0.1772 (0.1529)  acc1: 0.3333 (0.3684)  acc5: 0.6667 (0.7800)  time: 0.1023  data: 0.0696  max mem: 917
Test:  [ 580/2793]  eta: 0:04:09  loss: 0.1771 (0.1530)  acc1: 0.2500 (0.3668)  acc5: 0.5000 (0.7756)  time: 0.0997  data: 0.0665  max mem: 917
Test:  [ 590/2793]  eta: 0:04:08  loss: 0.1770 (0.1538)  acc1: 0.2500 (0.3652)  acc5: 0.5000 (0.7705)  time: 0.0943  data: 0.0612  max mem: 917
Test:  [ 600/2793]  eta: 0:04:06  loss: 0.1749 (0.1545)  acc1: 0.2500 (0.3666)  acc5: 0.7500 (0.7706)  time: 0.0945  data: 0.0613  max mem: 917
Test:  [ 610/2793]  eta: 0:04:05  loss: 0.1749 (0.1550)  acc1: 0.5000 (0.3665)  acc5: 0.7500 (0.7712)  time: 0.1034  data: 0.0705  max mem: 917
Test:  [ 620/2793]  eta: 0:04:03  loss: 0.1310 (0.1542)  acc1: 0.5000 (0.3670)  acc5: 0.8333 (0.7717)  time: 0.0994  data: 0.0659  max mem: 917
Test:  [ 630/2793]  eta: 0:04:01  loss: 0.1149 (0.1550)  acc1: 0.5000 (0.3684)  acc5: 0.7500 (0.7709)  time: 0.0943  data: 0.0624  max mem: 917
Test:  [ 640/2793]  eta: 0:04:00  loss: 0.2173 (0.1567)  acc1: 0.5000 (0.3680)  acc5: 0.7500 (0.7685)  time: 0.1135  data: 0.0820  max mem: 917
Test:  [ 650/2793]  eta: 0:03:58  loss: 0.1252 (0.1558)  acc1: 0.5000 (0.3689)  acc5: 1.0000 (0.7709)  time: 0.1021  data: 0.0697  max mem: 917
Test:  [ 660/2793]  eta: 0:03:57  loss: 0.0884 (0.1552)  acc1: 0.5000 (0.3694)  acc5: 1.0000 (0.7717)  time: 0.0951  data: 0.0607  max mem: 917
Test:  [ 670/2793]  eta: 0:03:55  loss: 0.1298 (0.1554)  acc1: 0.2500 (0.3669)  acc5: 0.5000 (0.7666)  time: 0.0973  data: 0.0599  max mem: 917
Test:  [ 680/2793]  eta: 0:03:54  loss: 0.1335 (0.1550)  acc1: 0.2500 (0.3674)  acc5: 0.7500 (0.7674)  time: 0.0913  data: 0.0550  max mem: 917
Test:  [ 690/2793]  eta: 0:03:53  loss: 0.1324 (0.1552)  acc1: 0.3333 (0.3666)  acc5: 0.7500 (0.7662)  time: 0.1052  data: 0.0700  max mem: 917
Test:  [ 700/2793]  eta: 0:03:52  loss: 0.1299 (0.1549)  acc1: 0.3333 (0.3661)  acc5: 0.8333 (0.7676)  time: 0.1169  data: 0.0822  max mem: 917
Test:  [ 710/2793]  eta: 0:03:51  loss: 0.1048 (0.1541)  acc1: 0.3333 (0.3676)  acc5: 1.0000 (0.7706)  time: 0.1196  data: 0.0863  max mem: 917
Test:  [ 720/2793]  eta: 0:03:49  loss: 0.1169 (0.1542)  acc1: 0.5000 (0.3690)  acc5: 1.0000 (0.7717)  time: 0.1051  data: 0.0736  max mem: 917
Test:  [ 730/2793]  eta: 0:03:48  loss: 0.1587 (0.1551)  acc1: 0.5000 (0.3680)  acc5: 0.7500 (0.7712)  time: 0.0959  data: 0.0648  max mem: 917
Test:  [ 740/2793]  eta: 0:03:46  loss: 0.1285 (0.1543)  acc1: 0.5000 (0.3694)  acc5: 1.0000 (0.7730)  time: 0.1006  data: 0.0670  max mem: 917
Test:  [ 750/2793]  eta: 0:03:45  loss: 0.1285 (0.1550)  acc1: 0.5000 (0.3698)  acc5: 1.0000 (0.7730)  time: 0.1025  data: 0.0682  max mem: 917
Test:  [ 760/2793]  eta: 0:03:44  loss: 0.1341 (0.1548)  acc1: 0.5000 (0.3705)  acc5: 0.7500 (0.7737)  time: 0.1020  data: 0.0696  max mem: 917
Test:  [ 770/2793]  eta: 0:03:43  loss: 0.1203 (0.1560)  acc1: 0.5000 (0.3701)  acc5: 0.8333 (0.7735)  time: 0.1075  data: 0.0768  max mem: 917
Test:  [ 780/2793]  eta: 0:03:42  loss: 0.1690 (0.1564)  acc1: 0.5000 (0.3712)  acc5: 0.8333 (0.7743)  time: 0.1116  data: 0.0801  max mem: 917
Test:  [ 790/2793]  eta: 0:03:40  loss: 0.2012 (0.1563)  acc1: 0.4000 (0.3709)  acc5: 0.7500 (0.7750)  time: 0.1009  data: 0.0689  max mem: 917
Test:  [ 800/2793]  eta: 0:03:39  loss: 0.1258 (0.1563)  acc1: 0.3333 (0.3699)  acc5: 0.7500 (0.7743)  time: 0.1054  data: 0.0734  max mem: 917
Test:  [ 810/2793]  eta: 0:03:38  loss: 0.1461 (0.1570)  acc1: 0.3333 (0.3699)  acc5: 0.7500 (0.7742)  time: 0.1039  data: 0.0713  max mem: 917
Test:  [ 820/2793]  eta: 0:03:36  loss: 0.1451 (0.1569)  acc1: 0.5000 (0.3708)  acc5: 1.0000 (0.7752)  time: 0.0908  data: 0.0588  max mem: 917
Test:  [ 830/2793]  eta: 0:03:35  loss: 0.1192 (0.1566)  acc1: 0.5000 (0.3710)  acc5: 1.0000 (0.7770)  time: 0.0968  data: 0.0622  max mem: 917
Test:  [ 840/2793]  eta: 0:03:34  loss: 0.1115 (0.1562)  acc1: 0.5000 (0.3722)  acc5: 1.0000 (0.7788)  time: 0.1067  data: 0.0710  max mem: 917
Test:  [ 850/2793]  eta: 0:03:32  loss: 0.1591 (0.1565)  acc1: 0.5000 (0.3723)  acc5: 0.7500 (0.7785)  time: 0.1053  data: 0.0710  max mem: 917
Test:  [ 860/2793]  eta: 0:03:32  loss: 0.1646 (0.1566)  acc1: 0.5000 (0.3732)  acc5: 0.7500 (0.7789)  time: 0.1104  data: 0.0751  max mem: 917
Test:  [ 870/2793]  eta: 0:03:30  loss: 0.1646 (0.1574)  acc1: 0.3333 (0.3727)  acc5: 0.7500 (0.7778)  time: 0.1099  data: 0.0737  max mem: 917
Test:  [ 880/2793]  eta: 0:03:29  loss: 0.1690 (0.1573)  acc1: 0.3333 (0.3728)  acc5: 0.8333 (0.7794)  time: 0.1007  data: 0.0663  max mem: 917
Test:  [ 890/2793]  eta: 0:03:27  loss: 0.1169 (0.1569)  acc1: 0.5000 (0.3741)  acc5: 1.0000 (0.7813)  time: 0.0959  data: 0.0630  max mem: 917
Test:  [ 900/2793]  eta: 0:03:26  loss: 0.1220 (0.1575)  acc1: 0.5000 (0.3731)  acc5: 1.0000 (0.7812)  time: 0.0946  data: 0.0601  max mem: 917
Test:  [ 910/2793]  eta: 0:03:25  loss: 0.1103 (0.1569)  acc1: 0.3333 (0.3737)  acc5: 1.0000 (0.7822)  time: 0.0972  data: 0.0615  max mem: 917
Test:  [ 920/2793]  eta: 0:03:23  loss: 0.1093 (0.1574)  acc1: 0.5000 (0.3740)  acc5: 0.8333 (0.7823)  time: 0.0967  data: 0.0626  max mem: 917
Test:  [ 930/2793]  eta: 0:03:22  loss: 0.1403 (0.1571)  acc1: 0.5000 (0.3751)  acc5: 0.7500 (0.7833)  time: 0.1068  data: 0.0739  max mem: 917
Test:  [ 940/2793]  eta: 0:03:21  loss: 0.1276 (0.1575)  acc1: 0.5000 (0.3754)  acc5: 0.8333 (0.7831)  time: 0.1073  data: 0.0731  max mem: 917
Test:  [ 950/2793]  eta: 0:03:20  loss: 0.1066 (0.1571)  acc1: 0.5000 (0.3761)  acc5: 1.0000 (0.7850)  time: 0.1010  data: 0.0665  max mem: 917
Test:  [ 960/2793]  eta: 0:03:19  loss: 0.1305 (0.1571)  acc1: 0.5000 (0.3761)  acc5: 0.8000 (0.7844)  time: 0.0980  data: 0.0640  max mem: 917
Test:  [ 970/2793]  eta: 0:03:17  loss: 0.1340 (0.1568)  acc1: 0.4000 (0.3764)  acc5: 0.7500 (0.7861)  time: 0.0933  data: 0.0591  max mem: 917
Test:  [ 980/2793]  eta: 0:03:16  loss: 0.1258 (0.1568)  acc1: 0.5000 (0.3776)  acc5: 1.0000 (0.7865)  time: 0.1026  data: 0.0700  max mem: 917
Test:  [ 990/2793]  eta: 0:03:15  loss: 0.1354 (0.1569)  acc1: 0.5000 (0.3779)  acc5: 0.7500 (0.7865)  time: 0.1074  data: 0.0757  max mem: 917
Test:  [1000/2793]  eta: 0:03:14  loss: 0.1201 (0.1566)  acc1: 0.5000 (0.3786)  acc5: 0.8333 (0.7874)  time: 0.0981  data: 0.0662  max mem: 917
Test:  [1010/2793]  eta: 0:03:13  loss: 0.1266 (0.1570)  acc1: 0.5000 (0.3780)  acc5: 0.8000 (0.7869)  time: 0.1033  data: 0.0712  max mem: 917
Test:  [1020/2793]  eta: 0:03:12  loss: 0.1411 (0.1572)  acc1: 0.5000 (0.3785)  acc5: 0.7500 (0.7871)  time: 0.1165  data: 0.0834  max mem: 917
Test:  [1030/2793]  eta: 0:03:11  loss: 0.1485 (0.1571)  acc1: 0.5000 (0.3794)  acc5: 1.0000 (0.7884)  time: 0.1104  data: 0.0778  max mem: 917
Test:  [1040/2793]  eta: 0:03:10  loss: 0.1549 (0.1574)  acc1: 0.3333 (0.3774)  acc5: 1.0000 (0.7876)  time: 0.1082  data: 0.0771  max mem: 917
Test:  [1050/2793]  eta: 0:03:08  loss: 0.1113 (0.1568)  acc1: 0.5000 (0.3786)  acc5: 1.0000 (0.7896)  time: 0.1097  data: 0.0790  max mem: 917
Test:  [1060/2793]  eta: 0:03:07  loss: 0.1013 (0.1567)  acc1: 0.5000 (0.3787)  acc5: 1.0000 (0.7904)  time: 0.1053  data: 0.0731  max mem: 917
Test:  [1070/2793]  eta: 0:03:06  loss: 0.1060 (0.1565)  acc1: 0.5000 (0.3791)  acc5: 1.0000 (0.7910)  time: 0.1039  data: 0.0709  max mem: 917
Test:  [1080/2793]  eta: 0:03:05  loss: 0.1077 (0.1561)  acc1: 0.5000 (0.3797)  acc5: 1.0000 (0.7924)  time: 0.0996  data: 0.0646  max mem: 917
Test:  [1090/2793]  eta: 0:03:03  loss: 0.1075 (0.1557)  acc1: 0.5000 (0.3800)  acc5: 1.0000 (0.7931)  time: 0.0882  data: 0.0536  max mem: 917
Test:  [1100/2793]  eta: 0:03:02  loss: 0.1114 (0.1555)  acc1: 0.5000 (0.3802)  acc5: 1.0000 (0.7932)  time: 0.0853  data: 0.0523  max mem: 917
Test:  [1110/2793]  eta: 0:03:01  loss: 0.1724 (0.1557)  acc1: 0.5000 (0.3797)  acc5: 0.7500 (0.7920)  time: 0.0923  data: 0.0595  max mem: 917
Test:  [1120/2793]  eta: 0:02:59  loss: 0.1724 (0.1558)  acc1: 0.2500 (0.3790)  acc5: 0.7500 (0.7905)  time: 0.0932  data: 0.0620  max mem: 917
Test:  [1130/2793]  eta: 0:02:58  loss: 0.1669 (0.1558)  acc1: 0.2500 (0.3779)  acc5: 0.5000 (0.7886)  time: 0.0910  data: 0.0615  max mem: 917
Test:  [1140/2793]  eta: 0:02:57  loss: 0.1351 (0.1558)  acc1: 0.2500 (0.3774)  acc5: 0.7500 (0.7881)  time: 0.0899  data: 0.0580  max mem: 917
Test:  [1150/2793]  eta: 0:02:56  loss: 0.1738 (0.1565)  acc1: 0.3333 (0.3775)  acc5: 0.7500 (0.7880)  time: 0.0989  data: 0.0650  max mem: 917
Test:  [1160/2793]  eta: 0:02:54  loss: 0.1728 (0.1563)  acc1: 0.3333 (0.3774)  acc5: 1.0000 (0.7889)  time: 0.0974  data: 0.0640  max mem: 917
Test:  [1170/2793]  eta: 0:02:53  loss: 0.1790 (0.1580)  acc1: 0.2500 (0.3759)  acc5: 0.7500 (0.7865)  time: 0.0869  data: 0.0533  max mem: 917
Test:  [1180/2793]  eta: 0:02:52  loss: 0.1570 (0.1577)  acc1: 0.2500 (0.3761)  acc5: 0.6667 (0.7865)  time: 0.0864  data: 0.0547  max mem: 917
Test:  [1190/2793]  eta: 0:02:51  loss: 0.1232 (0.1576)  acc1: 0.5000 (0.3769)  acc5: 0.7500 (0.7872)  time: 0.1005  data: 0.0677  max mem: 917
Test:  [1200/2793]  eta: 0:02:50  loss: 0.1678 (0.1584)  acc1: 0.5000 (0.3769)  acc5: 0.7500 (0.7864)  time: 0.1081  data: 0.0734  max mem: 917
Test:  [1210/2793]  eta: 0:02:48  loss: 0.1950 (0.1583)  acc1: 0.3333 (0.3770)  acc5: 0.7500 (0.7867)  time: 0.1006  data: 0.0660  max mem: 917
Test:  [1220/2793]  eta: 0:02:47  loss: 0.1287 (0.1581)  acc1: 0.5000 (0.3770)  acc5: 0.7500 (0.7860)  time: 0.0887  data: 0.0563  max mem: 917
Test:  [1230/2793]  eta: 0:02:46  loss: 0.0953 (0.1580)  acc1: 0.5000 (0.3769)  acc5: 0.7500 (0.7857)  time: 0.0895  data: 0.0566  max mem: 917
Test:  [1240/2793]  eta: 0:02:45  loss: 0.1297 (0.1580)  acc1: 0.5000 (0.3767)  acc5: 0.7500 (0.7851)  time: 0.1002  data: 0.0638  max mem: 917
Test:  [1250/2793]  eta: 0:02:43  loss: 0.1297 (0.1579)  acc1: 0.5000 (0.3768)  acc5: 0.7500 (0.7853)  time: 0.0969  data: 0.0598  max mem: 917
Test:  [1260/2793]  eta: 0:02:42  loss: 0.1296 (0.1583)  acc1: 0.5000 (0.3762)  acc5: 0.7500 (0.7848)  time: 0.0952  data: 0.0581  max mem: 917
Test:  [1270/2793]  eta: 0:02:41  loss: 0.1388 (0.1585)  acc1: 0.3333 (0.3758)  acc5: 0.8333 (0.7852)  time: 0.1077  data: 0.0715  max mem: 917
Test:  [1280/2793]  eta: 0:02:40  loss: 0.1059 (0.1581)  acc1: 0.5000 (0.3763)  acc5: 1.0000 (0.7862)  time: 0.1086  data: 0.0742  max mem: 917
Test:  [1290/2793]  eta: 0:02:39  loss: 0.0707 (0.1575)  acc1: 0.5000 (0.3769)  acc5: 1.0000 (0.7875)  time: 0.0981  data: 0.0647  max mem: 917
Test:  [1300/2793]  eta: 0:02:38  loss: 0.0954 (0.1577)  acc1: 0.5000 (0.3763)  acc5: 1.0000 (0.7866)  time: 0.0933  data: 0.0600  max mem: 917
Test:  [1310/2793]  eta: 0:02:36  loss: 0.1368 (0.1575)  acc1: 0.2500 (0.3763)  acc5: 0.7500 (0.7865)  time: 0.0879  data: 0.0542  max mem: 917
Test:  [1320/2793]  eta: 0:02:35  loss: 0.1430 (0.1575)  acc1: 0.2500 (0.3753)  acc5: 0.7500 (0.7856)  time: 0.0870  data: 0.0528  max mem: 917
Test:  [1330/2793]  eta: 0:02:34  loss: 0.1946 (0.1581)  acc1: 0.2500 (0.3742)  acc5: 0.5000 (0.7829)  time: 0.0911  data: 0.0556  max mem: 917
Test:  [1340/2793]  eta: 0:02:33  loss: 0.1832 (0.1582)  acc1: 0.2500 (0.3744)  acc5: 0.6667 (0.7835)  time: 0.1062  data: 0.0709  max mem: 917
Test:  [1350/2793]  eta: 0:02:32  loss: 0.1392 (0.1584)  acc1: 0.3333 (0.3741)  acc5: 1.0000 (0.7839)  time: 0.1102  data: 0.0768  max mem: 917
Test:  [1360/2793]  eta: 0:02:31  loss: 0.1411 (0.1582)  acc1: 0.3333 (0.3748)  acc5: 1.0000 (0.7846)  time: 0.1016  data: 0.0682  max mem: 917
Test:  [1370/2793]  eta: 0:02:30  loss: 0.0742 (0.1575)  acc1: 0.5000 (0.3757)  acc5: 1.0000 (0.7862)  time: 0.0919  data: 0.0559  max mem: 917
Test:  [1380/2793]  eta: 0:02:28  loss: 0.0569 (0.1567)  acc1: 0.5000 (0.3766)  acc5: 1.0000 (0.7877)  time: 0.0822  data: 0.0461  max mem: 917
Test:  [1390/2793]  eta: 0:02:27  loss: 0.0589 (0.1571)  acc1: 0.5000 (0.3761)  acc5: 1.0000 (0.7872)  time: 0.0930  data: 0.0603  max mem: 917
Test:  [1400/2793]  eta: 0:02:26  loss: 0.0886 (0.1567)  acc1: 0.5000 (0.3768)  acc5: 1.0000 (0.7883)  time: 0.1029  data: 0.0712  max mem: 917
Test:  [1410/2793]  eta: 0:02:25  loss: 0.0886 (0.1565)  acc1: 0.5000 (0.3766)  acc5: 1.0000 (0.7877)  time: 0.0965  data: 0.0630  max mem: 917
Test:  [1420/2793]  eta: 0:02:24  loss: 0.1270 (0.1564)  acc1: 0.5000 (0.3764)  acc5: 0.7500 (0.7875)  time: 0.1065  data: 0.0734  max mem: 917
Test:  [1430/2793]  eta: 0:02:23  loss: 0.1401 (0.1564)  acc1: 0.3333 (0.3763)  acc5: 1.0000 (0.7880)  time: 0.1127  data: 0.0821  max mem: 917
Test:  [1440/2793]  eta: 0:02:22  loss: 0.1558 (0.1567)  acc1: 0.3333 (0.3759)  acc5: 0.7500 (0.7869)  time: 0.1002  data: 0.0668  max mem: 917
Test:  [1450/2793]  eta: 0:02:21  loss: 0.1695 (0.1569)  acc1: 0.3333 (0.3760)  acc5: 0.7500 (0.7870)  time: 0.0964  data: 0.0625  max mem: 917
Test:  [1460/2793]  eta: 0:02:20  loss: 0.1503 (0.1571)  acc1: 0.5000 (0.3762)  acc5: 0.8333 (0.7871)  time: 0.0976  data: 0.0639  max mem: 917
Test:  [1470/2793]  eta: 0:02:19  loss: 0.1371 (0.1574)  acc1: 0.5000 (0.3762)  acc5: 0.8333 (0.7871)  time: 0.1042  data: 0.0682  max mem: 917
Test:  [1480/2793]  eta: 0:02:17  loss: 0.1371 (0.1574)  acc1: 0.3333 (0.3755)  acc5: 0.7500 (0.7867)  time: 0.1003  data: 0.0644  max mem: 917
Test:  [1490/2793]  eta: 0:02:16  loss: 0.1089 (0.1571)  acc1: 0.5000 (0.3760)  acc5: 0.7500 (0.7871)  time: 0.0847  data: 0.0503  max mem: 917
Test:  [1500/2793]  eta: 0:02:15  loss: 0.0921 (0.1570)  acc1: 0.5000 (0.3760)  acc5: 1.0000 (0.7873)  time: 0.0840  data: 0.0499  max mem: 917
Test:  [1510/2793]  eta: 0:02:14  loss: 0.0857 (0.1566)  acc1: 0.5000 (0.3763)  acc5: 1.0000 (0.7879)  time: 0.0859  data: 0.0500  max mem: 917
Test:  [1520/2793]  eta: 0:02:13  loss: 0.1349 (0.1568)  acc1: 0.3333 (0.3758)  acc5: 0.8333 (0.7875)  time: 0.0857  data: 0.0501  max mem: 917
Test:  [1530/2793]  eta: 0:02:11  loss: 0.1662 (0.1568)  acc1: 0.3333 (0.3762)  acc5: 0.7500 (0.7871)  time: 0.0863  data: 0.0523  max mem: 917
Test:  [1540/2793]  eta: 0:02:10  loss: 0.1599 (0.1569)  acc1: 0.5000 (0.3766)  acc5: 0.7500 (0.7872)  time: 0.0841  data: 0.0500  max mem: 917
Test:  [1550/2793]  eta: 0:02:09  loss: 0.1478 (0.1570)  acc1: 0.3333 (0.3758)  acc5: 0.7500 (0.7862)  time: 0.0918  data: 0.0589  max mem: 917
Test:  [1560/2793]  eta: 0:02:08  loss: 0.1384 (0.1571)  acc1: 0.2500 (0.3756)  acc5: 0.7500 (0.7859)  time: 0.1064  data: 0.0727  max mem: 917
Test:  [1570/2793]  eta: 0:02:07  loss: 0.1609 (0.1572)  acc1: 0.3333 (0.3751)  acc5: 0.7500 (0.7856)  time: 0.1040  data: 0.0683  max mem: 917
Test:  [1580/2793]  eta: 0:02:06  loss: 0.1617 (0.1572)  acc1: 0.3333 (0.3756)  acc5: 0.7500 (0.7857)  time: 0.1007  data: 0.0665  max mem: 917
Test:  [1590/2793]  eta: 0:02:05  loss: 0.1622 (0.1574)  acc1: 0.5000 (0.3756)  acc5: 0.7500 (0.7856)  time: 0.1016  data: 0.0690  max mem: 917
Test:  [1600/2793]  eta: 0:02:04  loss: 0.1372 (0.1571)  acc1: 0.5000 (0.3757)  acc5: 0.8333 (0.7857)  time: 0.0976  data: 0.0657  max mem: 917
Test:  [1610/2793]  eta: 0:02:03  loss: 0.0958 (0.1569)  acc1: 0.5000 (0.3763)  acc5: 1.0000 (0.7865)  time: 0.0930  data: 0.0596  max mem: 917
Test:  [1620/2793]  eta: 0:02:02  loss: 0.1309 (0.1570)  acc1: 0.5000 (0.3764)  acc5: 0.8000 (0.7861)  time: 0.0955  data: 0.0606  max mem: 917
Test:  [1630/2793]  eta: 0:02:01  loss: 0.1721 (0.1574)  acc1: 0.2500 (0.3761)  acc5: 0.7500 (0.7851)  time: 0.1113  data: 0.0762  max mem: 917
Test:  [1640/2793]  eta: 0:02:00  loss: 0.1683 (0.1576)  acc1: 0.2500 (0.3761)  acc5: 0.7500 (0.7850)  time: 0.1113  data: 0.0767  max mem: 917
Test:  [1650/2793]  eta: 0:01:59  loss: 0.1683 (0.1579)  acc1: 0.5000 (0.3763)  acc5: 0.7500 (0.7851)  time: 0.1113  data: 0.0772  max mem: 917
Test:  [1660/2793]  eta: 0:01:58  loss: 0.1702 (0.1580)  acc1: 0.4000 (0.3765)  acc5: 0.7500 (0.7846)  time: 0.1197  data: 0.0857  max mem: 917
Test:  [1670/2793]  eta: 0:01:57  loss: 0.0723 (0.1574)  acc1: 0.5000 (0.3772)  acc5: 1.0000 (0.7859)  time: 0.1022  data: 0.0674  max mem: 917
Test:  [1680/2793]  eta: 0:01:55  loss: 0.0595 (0.1572)  acc1: 0.5000 (0.3774)  acc5: 1.0000 (0.7866)  time: 0.0866  data: 0.0517  max mem: 917
Test:  [1690/2793]  eta: 0:01:54  loss: 0.1507 (0.1575)  acc1: 0.5000 (0.3775)  acc5: 0.7500 (0.7862)  time: 0.0923  data: 0.0566  max mem: 917
Test:  [1700/2793]  eta: 0:01:53  loss: 0.1598 (0.1577)  acc1: 0.3333 (0.3775)  acc5: 0.7500 (0.7859)  time: 0.0876  data: 0.0520  max mem: 917
Test:  [1710/2793]  eta: 0:01:52  loss: 0.1342 (0.1576)  acc1: 0.5000 (0.3778)  acc5: 0.7500 (0.7861)  time: 0.1015  data: 0.0654  max mem: 917
Test:  [1720/2793]  eta: 0:01:51  loss: 0.1406 (0.1579)  acc1: 0.5000 (0.3781)  acc5: 0.7500 (0.7860)  time: 0.1039  data: 0.0683  max mem: 917
Test:  [1730/2793]  eta: 0:01:50  loss: 0.1273 (0.1575)  acc1: 0.5000 (0.3785)  acc5: 1.0000 (0.7866)  time: 0.0857  data: 0.0521  max mem: 917
Test:  [1740/2793]  eta: 0:01:49  loss: 0.0878 (0.1573)  acc1: 0.5000 (0.3788)  acc5: 1.0000 (0.7869)  time: 0.0866  data: 0.0514  max mem: 917
Test:  [1750/2793]  eta: 0:01:48  loss: 0.1250 (0.1573)  acc1: 0.5000 (0.3787)  acc5: 0.7500 (0.7868)  time: 0.1000  data: 0.0640  max mem: 917
Test:  [1760/2793]  eta: 0:01:47  loss: 0.1823 (0.1579)  acc1: 0.2500 (0.3785)  acc5: 0.7500 (0.7859)  time: 0.1012  data: 0.0673  max mem: 917
Test:  [1770/2793]  eta: 0:01:46  loss: 0.2111 (0.1578)  acc1: 0.3333 (0.3786)  acc5: 0.7500 (0.7860)  time: 0.0899  data: 0.0556  max mem: 917
Test:  [1780/2793]  eta: 0:01:45  loss: 0.1517 (0.1579)  acc1: 0.3333 (0.3785)  acc5: 0.8333 (0.7860)  time: 0.1065  data: 0.0722  max mem: 917
Test:  [1790/2793]  eta: 0:01:43  loss: 0.1063 (0.1577)  acc1: 0.3333 (0.3780)  acc5: 0.8333 (0.7866)  time: 0.1052  data: 0.0706  max mem: 917
Test:  [1800/2793]  eta: 0:01:42  loss: 0.1089 (0.1577)  acc1: 0.3333 (0.3781)  acc5: 1.0000 (0.7868)  time: 0.0940  data: 0.0596  max mem: 917
Test:  [1810/2793]  eta: 0:01:41  loss: 0.1346 (0.1576)  acc1: 0.5000 (0.3783)  acc5: 1.0000 (0.7872)  time: 0.0943  data: 0.0623  max mem: 917
Test:  [1820/2793]  eta: 0:01:40  loss: 0.0948 (0.1572)  acc1: 0.5000 (0.3787)  acc5: 1.0000 (0.7879)  time: 0.0893  data: 0.0554  max mem: 917
Test:  [1830/2793]  eta: 0:01:39  loss: 0.0998 (0.1573)  acc1: 0.5000 (0.3786)  acc5: 0.7500 (0.7873)  time: 0.1014  data: 0.0641  max mem: 917
Test:  [1840/2793]  eta: 0:01:38  loss: 0.1667 (0.1574)  acc1: 0.2500 (0.3782)  acc5: 0.7500 (0.7870)  time: 0.1044  data: 0.0685  max mem: 917
Test:  [1850/2793]  eta: 0:01:37  loss: 0.1823 (0.1576)  acc1: 0.2500 (0.3780)  acc5: 0.7500 (0.7865)  time: 0.0950  data: 0.0623  max mem: 917
Test:  [1860/2793]  eta: 0:01:36  loss: 0.1642 (0.1579)  acc1: 0.2500 (0.3774)  acc5: 0.7500 (0.7862)  time: 0.1036  data: 0.0712  max mem: 917
Test:  [1870/2793]  eta: 0:01:35  loss: 0.1670 (0.1580)  acc1: 0.2500 (0.3771)  acc5: 0.7500 (0.7858)  time: 0.1158  data: 0.0809  max mem: 917
Test:  [1880/2793]  eta: 0:01:34  loss: 0.1810 (0.1585)  acc1: 0.2500 (0.3764)  acc5: 0.7500 (0.7846)  time: 0.1042  data: 0.0698  max mem: 917
Test:  [1890/2793]  eta: 0:01:33  loss: 0.1871 (0.1588)  acc1: 0.2500 (0.3761)  acc5: 0.7500 (0.7845)  time: 0.0941  data: 0.0608  max mem: 917
Test:  [1900/2793]  eta: 0:01:32  loss: 0.1589 (0.1588)  acc1: 0.5000 (0.3765)  acc5: 0.8333 (0.7850)  time: 0.0950  data: 0.0601  max mem: 917
Test:  [1910/2793]  eta: 0:01:31  loss: 0.1155 (0.1589)  acc1: 0.5000 (0.3765)  acc5: 1.0000 (0.7853)  time: 0.0988  data: 0.0641  max mem: 917
Test:  [1920/2793]  eta: 0:01:30  loss: 0.1039 (0.1588)  acc1: 0.5000 (0.3768)  acc5: 1.0000 (0.7861)  time: 0.0985  data: 0.0641  max mem: 917
Test:  [1930/2793]  eta: 0:01:29  loss: 0.1068 (0.1586)  acc1: 0.5000 (0.3772)  acc5: 1.0000 (0.7866)  time: 0.0998  data: 0.0654  max mem: 917
Test:  [1940/2793]  eta: 0:01:28  loss: 0.1295 (0.1588)  acc1: 0.5000 (0.3773)  acc5: 1.0000 (0.7865)  time: 0.1106  data: 0.0761  max mem: 917
Test:  [1950/2793]  eta: 0:01:27  loss: 0.1377 (0.1588)  acc1: 0.5000 (0.3775)  acc5: 1.0000 (0.7867)  time: 0.1050  data: 0.0675  max mem: 917
Test:  [1960/2793]  eta: 0:01:26  loss: 0.1432 (0.1588)  acc1: 0.4000 (0.3771)  acc5: 0.7500 (0.7860)  time: 0.0941  data: 0.0568  max mem: 917
Test:  [1970/2793]  eta: 0:01:25  loss: 0.1482 (0.1587)  acc1: 0.2500 (0.3770)  acc5: 0.7500 (0.7862)  time: 0.0975  data: 0.0623  max mem: 917
Test:  [1980/2793]  eta: 0:01:23  loss: 0.1609 (0.1589)  acc1: 0.2500 (0.3764)  acc5: 0.7500 (0.7858)  time: 0.0993  data: 0.0637  max mem: 917
Test:  [1990/2793]  eta: 0:01:22  loss: 0.1955 (0.1593)  acc1: 0.2500 (0.3758)  acc5: 0.6667 (0.7852)  time: 0.0937  data: 0.0583  max mem: 917
Test:  [2000/2793]  eta: 0:01:21  loss: 0.1699 (0.1591)  acc1: 0.3333 (0.3760)  acc5: 0.7500 (0.7856)  time: 0.0991  data: 0.0660  max mem: 917
Test:  [2010/2793]  eta: 0:01:20  loss: 0.0938 (0.1590)  acc1: 0.5000 (0.3761)  acc5: 1.0000 (0.7860)  time: 0.0970  data: 0.0639  max mem: 917
Test:  [2020/2793]  eta: 0:01:19  loss: 0.1434 (0.1592)  acc1: 0.3333 (0.3758)  acc5: 1.0000 (0.7855)  time: 0.1002  data: 0.0668  max mem: 917
Test:  [2030/2793]  eta: 0:01:18  loss: 0.1951 (0.1595)  acc1: 0.3333 (0.3758)  acc5: 0.6000 (0.7850)  time: 0.1052  data: 0.0730  max mem: 917
Test:  [2040/2793]  eta: 0:01:17  loss: 0.2412 (0.1600)  acc1: 0.2500 (0.3747)  acc5: 0.5000 (0.7825)  time: 0.0937  data: 0.0602  max mem: 917
Test:  [2050/2793]  eta: 0:01:16  loss: 0.1928 (0.1601)  acc1: 0.4000 (0.3750)  acc5: 0.7500 (0.7827)  time: 0.0949  data: 0.0600  max mem: 917
Test:  [2060/2793]  eta: 0:01:15  loss: 0.1459 (0.1604)  acc1: 0.5000 (0.3750)  acc5: 0.8000 (0.7827)  time: 0.1012  data: 0.0676  max mem: 917
Test:  [2070/2793]  eta: 0:01:14  loss: 0.1696 (0.1608)  acc1: 0.2500 (0.3741)  acc5: 0.6667 (0.7818)  time: 0.0957  data: 0.0634  max mem: 917
Test:  [2080/2793]  eta: 0:01:13  loss: 0.1696 (0.1611)  acc1: 0.2500 (0.3739)  acc5: 0.5000 (0.7814)  time: 0.0982  data: 0.0641  max mem: 917
Test:  [2090/2793]  eta: 0:01:12  loss: 0.2039 (0.1614)  acc1: 0.3333 (0.3738)  acc5: 0.7500 (0.7813)  time: 0.1070  data: 0.0727  max mem: 917
Test:  [2100/2793]  eta: 0:01:11  loss: 0.2039 (0.1616)  acc1: 0.3333 (0.3736)  acc5: 0.7500 (0.7810)  time: 0.1071  data: 0.0737  max mem: 917
Test:  [2110/2793]  eta: 0:01:10  loss: 0.1702 (0.1616)  acc1: 0.3333 (0.3734)  acc5: 0.7500 (0.7808)  time: 0.0997  data: 0.0652  max mem: 917
Test:  [2120/2793]  eta: 0:01:09  loss: 0.1960 (0.1620)  acc1: 0.3333 (0.3732)  acc5: 0.7500 (0.7800)  time: 0.1014  data: 0.0678  max mem: 917
Test:  [2130/2793]  eta: 0:01:08  loss: 0.1666 (0.1619)  acc1: 0.4000 (0.3734)  acc5: 0.8000 (0.7803)  time: 0.0980  data: 0.0645  max mem: 917
Test:  [2140/2793]  eta: 0:01:07  loss: 0.1338 (0.1622)  acc1: 0.5000 (0.3735)  acc5: 0.8000 (0.7799)  time: 0.0907  data: 0.0563  max mem: 917
Test:  [2150/2793]  eta: 0:01:06  loss: 0.1937 (0.1623)  acc1: 0.4000 (0.3733)  acc5: 0.7500 (0.7795)  time: 0.1023  data: 0.0685  max mem: 917
Test:  [2160/2793]  eta: 0:01:05  loss: 0.1857 (0.1624)  acc1: 0.3333 (0.3733)  acc5: 0.7500 (0.7798)  time: 0.1028  data: 0.0677  max mem: 917
Test:  [2170/2793]  eta: 0:01:04  loss: 0.2040 (0.1628)  acc1: 0.3333 (0.3729)  acc5: 0.8000 (0.7793)  time: 0.1006  data: 0.0666  max mem: 917
Test:  [2180/2793]  eta: 0:01:03  loss: 0.2114 (0.1630)  acc1: 0.3333 (0.3728)  acc5: 0.7500 (0.7788)  time: 0.0944  data: 0.0629  max mem: 917
Test:  [2190/2793]  eta: 0:01:02  loss: 0.1902 (0.1632)  acc1: 0.3333 (0.3724)  acc5: 0.6667 (0.7781)  time: 0.0961  data: 0.0650  max mem: 917
Test:  [2200/2793]  eta: 0:01:01  loss: 0.1613 (0.1632)  acc1: 0.3333 (0.3725)  acc5: 0.7500 (0.7784)  time: 0.1067  data: 0.0782  max mem: 917
Test:  [2210/2793]  eta: 0:00:59  loss: 0.1593 (0.1632)  acc1: 0.3333 (0.3723)  acc5: 1.0000 (0.7785)  time: 0.0999  data: 0.0711  max mem: 917
Test:  [2220/2793]  eta: 0:00:58  loss: 0.1688 (0.1633)  acc1: 0.3333 (0.3724)  acc5: 0.8333 (0.7787)  time: 0.0932  data: 0.0615  max mem: 917
Test:  [2230/2793]  eta: 0:00:57  loss: 0.1483 (0.1632)  acc1: 0.5000 (0.3727)  acc5: 0.8333 (0.7790)  time: 0.1052  data: 0.0738  max mem: 917
Test:  [2240/2793]  eta: 0:00:56  loss: 0.1477 (0.1633)  acc1: 0.4000 (0.3726)  acc5: 0.8333 (0.7793)  time: 0.1104  data: 0.0785  max mem: 917
Test:  [2250/2793]  eta: 0:00:55  loss: 0.1778 (0.1635)  acc1: 0.2500 (0.3722)  acc5: 0.8333 (0.7789)  time: 0.1045  data: 0.0738  max mem: 917
Test:  [2260/2793]  eta: 0:00:54  loss: 0.1793 (0.1636)  acc1: 0.3333 (0.3724)  acc5: 0.7500 (0.7788)  time: 0.1059  data: 0.0756  max mem: 917
Test:  [2270/2793]  eta: 0:00:53  loss: 0.1697 (0.1637)  acc1: 0.4000 (0.3722)  acc5: 0.7500 (0.7788)  time: 0.1003  data: 0.0658  max mem: 917
Test:  [2280/2793]  eta: 0:00:52  loss: 0.1765 (0.1639)  acc1: 0.3333 (0.3721)  acc5: 0.7500 (0.7785)  time: 0.0955  data: 0.0606  max mem: 917
Test:  [2290/2793]  eta: 0:00:51  loss: 0.1733 (0.1640)  acc1: 0.4000 (0.3721)  acc5: 0.8333 (0.7788)  time: 0.0949  data: 0.0623  max mem: 917
Test:  [2300/2793]  eta: 0:00:50  loss: 0.1733 (0.1640)  acc1: 0.4000 (0.3721)  acc5: 0.8333 (0.7789)  time: 0.1038  data: 0.0722  max mem: 917
Test:  [2310/2793]  eta: 0:00:49  loss: 0.1865 (0.1642)  acc1: 0.3333 (0.3723)  acc5: 0.8000 (0.7791)  time: 0.1133  data: 0.0827  max mem: 917
Test:  [2320/2793]  eta: 0:00:48  loss: 0.1648 (0.1641)  acc1: 0.3333 (0.3722)  acc5: 0.8333 (0.7792)  time: 0.1123  data: 0.0822  max mem: 917
Test:  [2330/2793]  eta: 0:00:47  loss: 0.1356 (0.1641)  acc1: 0.3333 (0.3721)  acc5: 0.8333 (0.7791)  time: 0.1017  data: 0.0705  max mem: 917
Test:  [2340/2793]  eta: 0:00:46  loss: 0.1436 (0.1641)  acc1: 0.4000 (0.3723)  acc5: 0.8000 (0.7794)  time: 0.0953  data: 0.0638  max mem: 917
Test:  [2350/2793]  eta: 0:00:45  loss: 0.1634 (0.1644)  acc1: 0.4000 (0.3719)  acc5: 0.7500 (0.7787)  time: 0.1038  data: 0.0734  max mem: 917
Test:  [2360/2793]  eta: 0:00:44  loss: 0.1625 (0.1645)  acc1: 0.3333 (0.3717)  acc5: 0.7500 (0.7786)  time: 0.1140  data: 0.0858  max mem: 917
Test:  [2370/2793]  eta: 0:00:43  loss: 0.1372 (0.1644)  acc1: 0.5000 (0.3721)  acc5: 1.0000 (0.7793)  time: 0.1112  data: 0.0836  max mem: 917
Test:  [2380/2793]  eta: 0:00:42  loss: 0.1662 (0.1646)  acc1: 0.5000 (0.3724)  acc5: 0.7500 (0.7791)  time: 0.0952  data: 0.0628  max mem: 917
Test:  [2390/2793]  eta: 0:00:41  loss: 0.1789 (0.1647)  acc1: 0.5000 (0.3725)  acc5: 0.7500 (0.7792)  time: 0.0954  data: 0.0611  max mem: 917
Test:  [2400/2793]  eta: 0:00:40  loss: 0.1533 (0.1646)  acc1: 0.4000 (0.3725)  acc5: 0.8333 (0.7794)  time: 0.1038  data: 0.0707  max mem: 917
Test:  [2410/2793]  eta: 0:00:39  loss: 0.1643 (0.1649)  acc1: 0.3333 (0.3723)  acc5: 0.7500 (0.7791)  time: 0.1049  data: 0.0737  max mem: 917
Test:  [2420/2793]  eta: 0:00:38  loss: 0.1657 (0.1649)  acc1: 0.3333 (0.3721)  acc5: 0.8000 (0.7794)  time: 0.1042  data: 0.0742  max mem: 917
Test:  [2430/2793]  eta: 0:00:37  loss: 0.1584 (0.1649)  acc1: 0.4000 (0.3720)  acc5: 0.7500 (0.7792)  time: 0.0938  data: 0.0618  max mem: 917
Test:  [2440/2793]  eta: 0:00:36  loss: 0.1525 (0.1650)  acc1: 0.3333 (0.3721)  acc5: 0.7500 (0.7791)  time: 0.0947  data: 0.0600  max mem: 917
Test:  [2450/2793]  eta: 0:00:35  loss: 0.1451 (0.1651)  acc1: 0.3333 (0.3721)  acc5: 0.7500 (0.7786)  time: 0.1026  data: 0.0693  max mem: 917
Test:  [2460/2793]  eta: 0:00:34  loss: 0.1451 (0.1651)  acc1: 0.4000 (0.3723)  acc5: 0.7500 (0.7785)  time: 0.1035  data: 0.0712  max mem: 917
Test:  [2470/2793]  eta: 0:00:33  loss: 0.1762 (0.1652)  acc1: 0.5000 (0.3724)  acc5: 0.7500 (0.7785)  time: 0.1019  data: 0.0693  max mem: 917
Test:  [2480/2793]  eta: 0:00:32  loss: 0.1447 (0.1652)  acc1: 0.3333 (0.3724)  acc5: 0.8333 (0.7785)  time: 0.1012  data: 0.0690  max mem: 917
Test:  [2490/2793]  eta: 0:00:31  loss: 0.1739 (0.1655)  acc1: 0.3333 (0.3722)  acc5: 0.7500 (0.7781)  time: 0.0955  data: 0.0621  max mem: 917
Test:  [2500/2793]  eta: 0:00:30  loss: 0.1739 (0.1655)  acc1: 0.3333 (0.3721)  acc5: 0.7500 (0.7779)  time: 0.0846  data: 0.0523  max mem: 917
Test:  [2510/2793]  eta: 0:00:29  loss: 0.1612 (0.1655)  acc1: 0.3333 (0.3718)  acc5: 0.7500 (0.7779)  time: 0.0956  data: 0.0632  max mem: 917
Test:  [2520/2793]  eta: 0:00:28  loss: 0.1631 (0.1658)  acc1: 0.2500 (0.3714)  acc5: 0.7500 (0.7777)  time: 0.1018  data: 0.0693  max mem: 917
Test:  [2530/2793]  eta: 0:00:27  loss: 0.1663 (0.1658)  acc1: 0.3333 (0.3714)  acc5: 0.7500 (0.7778)  time: 0.1019  data: 0.0717  max mem: 917
Test:  [2540/2793]  eta: 0:00:25  loss: 0.2037 (0.1662)  acc1: 0.3333 (0.3712)  acc5: 0.6000 (0.7766)  time: 0.1086  data: 0.0776  max mem: 917
Test:  [2550/2793]  eta: 0:00:24  loss: 0.1843 (0.1662)  acc1: 0.3333 (0.3713)  acc5: 0.6667 (0.7769)  time: 0.1052  data: 0.0723  max mem: 917
Test:  [2560/2793]  eta: 0:00:23  loss: 0.1531 (0.1663)  acc1: 0.3333 (0.3710)  acc5: 0.7500 (0.7764)  time: 0.0985  data: 0.0653  max mem: 917
Test:  [2570/2793]  eta: 0:00:22  loss: 0.2060 (0.1665)  acc1: 0.3333 (0.3707)  acc5: 0.6000 (0.7759)  time: 0.1004  data: 0.0682  max mem: 917
Test:  [2580/2793]  eta: 0:00:21  loss: 0.1583 (0.1664)  acc1: 0.3333 (0.3709)  acc5: 0.8333 (0.7763)  time: 0.1038  data: 0.0712  max mem: 917
Test:  [2590/2793]  eta: 0:00:20  loss: 0.1193 (0.1664)  acc1: 0.5000 (0.3709)  acc5: 0.7500 (0.7761)  time: 0.0975  data: 0.0616  max mem: 917
Test:  [2600/2793]  eta: 0:00:19  loss: 0.1629 (0.1664)  acc1: 0.4000 (0.3709)  acc5: 0.7500 (0.7761)  time: 0.0946  data: 0.0571  max mem: 917
Test:  [2610/2793]  eta: 0:00:18  loss: 0.1742 (0.1664)  acc1: 0.3333 (0.3707)  acc5: 0.7500 (0.7757)  time: 0.0903  data: 0.0562  max mem: 917
Test:  [2620/2793]  eta: 0:00:17  loss: 0.1425 (0.1664)  acc1: 0.4000 (0.3709)  acc5: 0.7500 (0.7759)  time: 0.0942  data: 0.0623  max mem: 917
Test:  [2630/2793]  eta: 0:00:16  loss: 0.1355 (0.1664)  acc1: 0.5000 (0.3710)  acc5: 1.0000 (0.7760)  time: 0.1000  data: 0.0668  max mem: 917
Test:  [2640/2793]  eta: 0:00:15  loss: 0.1906 (0.1666)  acc1: 0.2500 (0.3706)  acc5: 0.7500 (0.7752)  time: 0.0998  data: 0.0660  max mem: 917
Test:  [2650/2793]  eta: 0:00:14  loss: 0.1944 (0.1667)  acc1: 0.2500 (0.3705)  acc5: 0.7500 (0.7749)  time: 0.1119  data: 0.0786  max mem: 917
Test:  [2660/2793]  eta: 0:00:13  loss: 0.1594 (0.1667)  acc1: 0.3333 (0.3703)  acc5: 0.8333 (0.7752)  time: 0.1165  data: 0.0827  max mem: 917
Test:  [2670/2793]  eta: 0:00:12  loss: 0.1594 (0.1668)  acc1: 0.2500 (0.3701)  acc5: 0.7500 (0.7742)  time: 0.1054  data: 0.0712  max mem: 917
Test:  [2680/2793]  eta: 0:00:11  loss: 0.2206 (0.1671)  acc1: 0.3333 (0.3702)  acc5: 0.6000 (0.7739)  time: 0.1004  data: 0.0642  max mem: 917
Test:  [2690/2793]  eta: 0:00:10  loss: 0.2179 (0.1674)  acc1: 0.3333 (0.3696)  acc5: 0.6667 (0.7730)  time: 0.1002  data: 0.0617  max mem: 917
Test:  [2700/2793]  eta: 0:00:09  loss: 0.1981 (0.1675)  acc1: 0.2500 (0.3696)  acc5: 0.6667 (0.7728)  time: 0.0942  data: 0.0597  max mem: 917
Test:  [2710/2793]  eta: 0:00:08  loss: 0.2057 (0.1676)  acc1: 0.4000 (0.3698)  acc5: 0.7500 (0.7726)  time: 0.0994  data: 0.0689  max mem: 917
Test:  [2720/2793]  eta: 0:00:07  loss: 0.2043 (0.1677)  acc1: 0.3333 (0.3697)  acc5: 0.6667 (0.7719)  time: 0.1036  data: 0.0723  max mem: 917
Test:  [2730/2793]  eta: 0:00:06  loss: 0.1590 (0.1678)  acc1: 0.3333 (0.3697)  acc5: 0.7500 (0.7719)  time: 0.1011  data: 0.0687  max mem: 917
Test:  [2740/2793]  eta: 0:00:05  loss: 0.1562 (0.1679)  acc1: 0.5000 (0.3697)  acc5: 0.7500 (0.7716)  time: 0.1081  data: 0.0751  max mem: 917
Test:  [2750/2793]  eta: 0:00:04  loss: 0.1686 (0.1679)  acc1: 0.4000 (0.3697)  acc5: 0.7500 (0.7717)  time: 0.1035  data: 0.0699  max mem: 917
Test:  [2760/2793]  eta: 0:00:03  loss: 0.1362 (0.1678)  acc1: 0.3333 (0.3697)  acc5: 0.8333 (0.7719)  time: 0.0984  data: 0.0640  max mem: 917
Test:  [2770/2793]  eta: 0:00:02  loss: 0.1663 (0.1682)  acc1: 0.3333 (0.3697)  acc5: 0.8000 (0.7718)  time: 0.0946  data: 0.0612  max mem: 917
Test:  [2780/2793]  eta: 0:00:01  loss: 0.1663 (0.1682)  acc1: 0.4000 (0.3697)  acc5: 0.7500 (0.7715)  time: 0.0944  data: 0.0627  max mem: 917
Test:  [2790/2793]  eta: 0:00:00  loss: 0.1598 (0.1683)  acc1: 0.3333 (0.3695)  acc5: 0.7500 (0.7716)  time: 0.0929  data: 0.0645  max mem: 917
Test:  [2792/2793]  eta: 0:00:00  loss: 0.1672 (0.1683)  acc1: 0.3333 (0.3695)  acc5: 0.7500 (0.7715)  time: 0.0902  data: 0.0638  max mem: 917
Test: Total time: 0:04:47 (0.1028 s / it)
* Acc@1 0.369 Acc@5 0.772 loss 0.168
Start merging results...
Reading individual output files
Computing final results
5586
