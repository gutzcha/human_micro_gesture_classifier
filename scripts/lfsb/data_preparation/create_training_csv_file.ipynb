{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from random_erasing import RandomErasing\n",
    "import warnings\n",
    "from decord import VideoReader, cpu\n",
    "from torch.utils.data import Dataset\n",
    "import video_transforms as video_transforms \n",
    "import volume_transforms as volume_transforms\n",
    "\n",
    "\n",
    "class LSFBVideoClsDataset(Dataset):\n",
    "    \"\"\"Load your own video classification dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, anno_path, data_path, mode='train', clip_len=8,\n",
    "                crop_size=224, short_side_size=256, new_height=256,\n",
    "                new_width=340, keep_aspect_ratio=True, num_segment=1,\n",
    "                num_crop=1, test_num_segment=10, test_num_crop=3, args=None):\n",
    "        self.anno_path = anno_path\n",
    "        self.data_path = data_path\n",
    "        self.mode = mode\n",
    "        self.clip_len = clip_len\n",
    "        self.crop_size = crop_size\n",
    "        self.short_side_size = short_side_size\n",
    "        self.new_height = new_height\n",
    "        self.new_width = new_width\n",
    "        self.keep_aspect_ratio = keep_aspect_ratio\n",
    "        self.num_segment = num_segment\n",
    "        self.test_num_segment = test_num_segment\n",
    "        self.num_crop = num_crop\n",
    "        self.test_num_crop = test_num_crop\n",
    "        self.args = args\n",
    "        self.aug = False\n",
    "        self.rand_erase = False\n",
    "        if self.mode in ['train']:\n",
    "            self.aug = True\n",
    "            if self.args.reprob > 0:\n",
    "                self.rand_erase = True\n",
    "        if VideoReader is None:\n",
    "            raise ImportError(\"Unable to import `decord` which is required to read videos.\")\n",
    "\n",
    "        import pandas as pd\n",
    "        cleaned = pd.read_csv(self.anno_path, header=None, delimiter=' ')\n",
    "        self.dataset_samples = list(cleaned.values[:, 0])\n",
    "        self.label_array = list(cleaned.values[:, 1])\n",
    "\n",
    "        if (mode == 'train'):\n",
    "            pass\n",
    "\n",
    "        elif (mode == 'validation'):\n",
    "            self.data_transform = video_transforms.Compose([\n",
    "                video_transforms.Resize(self.short_side_size, interpolation='bilinear'),\n",
    "                video_transforms.CenterCrop(size=(self.crop_size, self.crop_size)),\n",
    "                volume_transforms.ClipToTensor(),\n",
    "                video_transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                        std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        elif mode == 'test':\n",
    "            self.data_resize = video_transforms.Compose([\n",
    "                video_transforms.Resize(size=(short_side_size), interpolation='bilinear')\n",
    "            ])\n",
    "            self.data_transform = video_transforms.Compose([\n",
    "                volume_transforms.ClipToTensor(),\n",
    "                video_transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                        std=[0.229, 0.224, 0.225])\n",
    "            ])\n",
    "            self.test_seg = []\n",
    "            self.test_dataset = []\n",
    "            self.test_label_array = []\n",
    "            for ck in range(self.test_num_segment):\n",
    "                for cp in range(self.test_num_crop):\n",
    "                    for idx in range(len(self.label_array)):\n",
    "                        sample_label = self.label_array[idx]\n",
    "                        self.test_label_array.append(sample_label)\n",
    "                        self.test_dataset.append(self.dataset_samples[idx])\n",
    "                        self.test_seg.append((ck, cp))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.mode == 'train':\n",
    "            args = self.args \n",
    "            scale_t = 1\n",
    "\n",
    "            sample = self.dataset_samples[index]\n",
    "            buffer = self.loadvideo_decord(sample, sample_rate_scale=scale_t) # T H W C\n",
    "            if len(buffer) == 0:\n",
    "                while len(buffer) == 0:\n",
    "                    warnings.warn(\"video {} not correctly loaded during training\".format(sample))\n",
    "                    index = np.random.randint(self.__len__())\n",
    "                    sample = self.dataset_samples[index]\n",
    "                    buffer = self.loadvideo_decord(sample, sample_rate_scale=scale_t)\n",
    "\n",
    "            if args.num_sample > 1:\n",
    "                frame_list = []\n",
    "                label_list = []\n",
    "                index_list = []\n",
    "                for _ in range(args.num_sample):\n",
    "                    new_frames = self._aug_frame(buffer, args)\n",
    "                    label = self.label_array[index]\n",
    "                    frame_list.append(new_frames)\n",
    "                    label_list.append(label)\n",
    "                    index_list.append(index)\n",
    "                return frame_list, label_list, index_list, {}\n",
    "            else:\n",
    "                buffer = self._aug_frame(buffer, args)\n",
    "            \n",
    "            return buffer, self.label_array[index], index, {}\n",
    "\n",
    "        elif self.mode == 'validation':\n",
    "            sample = self.dataset_samples[index]\n",
    "            buffer = self.loadvideo_decord(sample)\n",
    "            if len(buffer) == 0:\n",
    "                while len(buffer) == 0:\n",
    "                    warnings.warn(\"video {} not correctly loaded during validation\".format(sample))\n",
    "                    index = np.random.randint(self.__len__())\n",
    "                    sample = self.dataset_samples[index]\n",
    "                    buffer = self.loadvideo_decord(sample)\n",
    "            buffer = self.data_transform(buffer)\n",
    "            return buffer, self.label_array[index], sample.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "        elif self.mode == 'test':\n",
    "            sample = self.test_dataset[index]\n",
    "            chunk_nb, split_nb = self.test_seg[index]\n",
    "            buffer = self.loadvideo_decord(sample)\n",
    "\n",
    "            while len(buffer) == 0:\n",
    "                warnings.warn(\"video {}, temporal {}, spatial {} not found during testing\".format(\\\n",
    "                    str(self.test_dataset[index]), chunk_nb, split_nb))\n",
    "                index = np.random.randint(self.__len__())\n",
    "                sample = self.test_dataset[index]\n",
    "                chunk_nb, split_nb = self.test_seg[index]\n",
    "                buffer = self.loadvideo_decord(sample)\n",
    "\n",
    "            buffer = self.data_resize(buffer)\n",
    "            if isinstance(buffer, list):\n",
    "                buffer = np.stack(buffer, 0)\n",
    "\n",
    "            spatial_step = 1.0 * (max(buffer.shape[1], buffer.shape[2]) - self.short_side_size) \\\n",
    "                                / (self.test_num_crop - 1)\n",
    "            temporal_start = chunk_nb # 0/1\n",
    "            spatial_start = int(split_nb * spatial_step)\n",
    "            if buffer.shape[1] >= buffer.shape[2]:\n",
    "                buffer = buffer[temporal_start::2, \\\n",
    "                       spatial_start:spatial_start + self.short_side_size, :, :]\n",
    "            else:\n",
    "                buffer = buffer[temporal_start::2, \\\n",
    "                       :, spatial_start:spatial_start + self.short_side_size, :]\n",
    "\n",
    "            buffer = self.data_transform(buffer)\n",
    "            return buffer, self.test_label_array[index], sample.split(\"/\")[-1].split(\".\")[0], \\\n",
    "                   chunk_nb, split_nb\n",
    "        else:\n",
    "            raise NameError('mode {} unkown'.format(self.mode))\n",
    "\n",
    "    def _aug_frame(\n",
    "        self,\n",
    "        buffer,\n",
    "        args,\n",
    "    ):\n",
    "\n",
    "        aug_transform = video_transforms.create_random_augment(\n",
    "            input_size=(self.crop_size, self.crop_size),\n",
    "            auto_augment=args.aa,\n",
    "            interpolation=args.train_interpolation,\n",
    "        )\n",
    "\n",
    "        buffer = [\n",
    "            transforms.ToPILImage()(frame) for frame in buffer\n",
    "        ]\n",
    "\n",
    "        buffer = aug_transform(buffer)\n",
    "\n",
    "        buffer = [transforms.ToTensor()(img) for img in buffer]\n",
    "        buffer = torch.stack(buffer) # T C H W\n",
    "        buffer = buffer.permute(0, 2, 3, 1) # T H W C \n",
    "        \n",
    "        # T H W C \n",
    "        buffer = tensor_normalize(\n",
    "            buffer, [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
    "        )\n",
    "        # T H W C -> C T H W.\n",
    "        buffer = buffer.permute(3, 0, 1, 2)\n",
    "        # Perform data augmentation.\n",
    "        scl, asp = (\n",
    "            [0.08, 1.0],\n",
    "            [0.75, 1.3333],\n",
    "        )\n",
    "\n",
    "        buffer = spatial_sampling(\n",
    "            buffer,\n",
    "            spatial_idx=-1,\n",
    "            min_scale=256,\n",
    "            max_scale=320,\n",
    "            crop_size=self.crop_size,\n",
    "            random_horizontal_flip=False if args.data_set == 'SSV2' else True,\n",
    "            inverse_uniform_sampling=False,\n",
    "            aspect_ratio=asp,\n",
    "            scale=scl,\n",
    "            motion_shift=False\n",
    "        )\n",
    "\n",
    "        if self.rand_erase:\n",
    "            erase_transform = RandomErasing(\n",
    "                args.reprob,\n",
    "                mode=args.remode,\n",
    "                max_count=args.recount,\n",
    "                num_splits=args.recount,\n",
    "                device=\"cpu\",\n",
    "            )\n",
    "            buffer = buffer.permute(1, 0, 2, 3)\n",
    "            buffer = erase_transform(buffer)\n",
    "            buffer = buffer.permute(1, 0, 2, 3)\n",
    "\n",
    "        return buffer\n",
    "\n",
    "\n",
    "    def loadvideo_decord(self, sample, sample_rate_scale=1):\n",
    "        \"\"\"Load video content using Decord\"\"\"\n",
    "        fname = sample\n",
    "\n",
    "        if not (os.path.exists(fname)):\n",
    "            return []\n",
    "\n",
    "        # avoid hanging issue\n",
    "        if os.path.getsize(fname) < 1 * 1024:\n",
    "            print('SKIP: ', fname, \" - \", os.path.getsize(fname))\n",
    "            return []\n",
    "        try:\n",
    "            if self.keep_aspect_ratio:\n",
    "                vr = VideoReader(fname, num_threads=1, ctx=cpu(0))\n",
    "            else:\n",
    "                vr = VideoReader(fname, width=self.new_width, height=self.new_height,\n",
    "                                 num_threads=1, ctx=cpu(0))\n",
    "        except:\n",
    "            print(\"video cannot be loaded by decord: \", fname)\n",
    "            return []\n",
    "\n",
    "        if self.mode == 'test':\n",
    "            all_index = []\n",
    "            tick = len(vr) / float(self.num_segment)\n",
    "            all_index = list(np.array([int(tick / 2.0 + tick * x) for x in range(self.num_segment)] +\n",
    "                               [int(tick * x) for x in range(self.num_segment)]))\n",
    "            while len(all_index) < (self.num_segment * self.test_num_segment):\n",
    "                all_index.append(all_index[-1])\n",
    "            all_index = list(np.sort(np.array(all_index))) \n",
    "            vr.seek(0)\n",
    "            buffer = vr.get_batch(all_index).asnumpy()\n",
    "            return buffer\n",
    "\n",
    "        # handle temporal segments\n",
    "        average_duration = len(vr) // self.num_segment\n",
    "        all_index = []\n",
    "        if average_duration > 0:\n",
    "            all_index += list(np.multiply(list(range(self.num_segment)), average_duration) + np.random.randint(average_duration,\n",
    "                                                                                                        size=self.num_segment))\n",
    "        elif len(vr) > self.num_segment:\n",
    "            all_index += list(np.sort(np.random.randint(len(vr), size=self.num_segment)))\n",
    "        else:\n",
    "            all_index += list(np.zeros((self.num_segment,)))\n",
    "        all_index = list(np.array(all_index)) \n",
    "        vr.seek(0)\n",
    "        buffer = vr.get_batch(all_index).asnumpy()\n",
    "        return buffer\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.mode != 'test':\n",
    "            return len(self.dataset_samples)\n",
    "        else:\n",
    "            return len(self.test_dataset)\n",
    "\n",
    "\n",
    "def spatial_sampling(\n",
    "    frames,\n",
    "    spatial_idx=-1,\n",
    "    min_scale=256,\n",
    "    max_scale=320,\n",
    "    crop_size=224,\n",
    "    random_horizontal_flip=True,\n",
    "    inverse_uniform_sampling=False,\n",
    "    aspect_ratio=None,\n",
    "    scale=None,\n",
    "    motion_shift=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform spatial sampling on the given video frames. If spatial_idx is\n",
    "    -1, perform random scale, random crop, and random flip on the given\n",
    "    frames. If spatial_idx is 0, 1, or 2, perform spatial uniform sampling\n",
    "    with the given spatial_idx.\n",
    "    Args:\n",
    "        frames (tensor): frames of images sampled from the video. The\n",
    "            dimension is `num frames` x `height` x `width` x `channel`.\n",
    "        spatial_idx (int): if -1, perform random spatial sampling. If 0, 1,\n",
    "            or 2, perform left, center, right crop if width is larger than\n",
    "            height, and perform top, center, buttom crop if height is larger\n",
    "            than width.\n",
    "        min_scale (int): the minimal size of scaling.\n",
    "        max_scale (int): the maximal size of scaling.\n",
    "        crop_size (int): the size of height and width used to crop the\n",
    "            frames.\n",
    "        inverse_uniform_sampling (bool): if True, sample uniformly in\n",
    "            [1 / max_scale, 1 / min_scale] and take a reciprocal to get the\n",
    "            scale. If False, take a uniform sample from [min_scale,\n",
    "            max_scale].\n",
    "        aspect_ratio (list): Aspect ratio range for resizing.\n",
    "        scale (list): Scale range for resizing.\n",
    "        motion_shift (bool): Whether to apply motion shift for resizing.\n",
    "    Returns:\n",
    "        frames (tensor): spatially sampled frames.\n",
    "    \"\"\"\n",
    "    assert spatial_idx in [-1, 0, 1, 2]\n",
    "    if spatial_idx == -1:\n",
    "        if aspect_ratio is None and scale is None:\n",
    "            frames, _ = video_transforms.random_short_side_scale_jitter(\n",
    "                images=frames,\n",
    "                min_size=min_scale,\n",
    "                max_size=max_scale,\n",
    "                inverse_uniform_sampling=inverse_uniform_sampling,\n",
    "            )\n",
    "            frames, _ = video_transforms.random_crop(frames, crop_size)\n",
    "        else:\n",
    "            transform_func = (\n",
    "                video_transforms.random_resized_crop_with_shift\n",
    "                if motion_shift\n",
    "                else video_transforms.random_resized_crop\n",
    "            )\n",
    "            frames = transform_func(\n",
    "                images=frames,\n",
    "                target_height=crop_size,\n",
    "                target_width=crop_size,\n",
    "                scale=scale,\n",
    "                ratio=aspect_ratio,\n",
    "            )\n",
    "        if random_horizontal_flip:\n",
    "            frames, _ = video_transforms.horizontal_flip(0.5, frames)\n",
    "    else:\n",
    "        # The testing is deterministic and no jitter should be performed.\n",
    "        # min_scale, max_scale, and crop_size are expect to be the same.\n",
    "        assert len({min_scale, max_scale, crop_size}) == 1\n",
    "        frames, _ = video_transforms.random_short_side_scale_jitter(\n",
    "            frames, min_scale, max_scale\n",
    "        )\n",
    "        frames, _ = video_transforms.uniform_crop(frames, crop_size, spatial_idx)\n",
    "    return frames\n",
    "\n",
    "\n",
    "def tensor_normalize(tensor, mean, std):\n",
    "    \"\"\"\n",
    "    Normalize a given tensor by subtracting the mean and dividing the std.\n",
    "    Args:\n",
    "        tensor (tensor): tensor to normalize.\n",
    "        mean (tensor or list): mean value to subtract.\n",
    "        std (tensor or list): std to divide.\n",
    "    \"\"\"\n",
    "    if tensor.dtype == torch.uint8:\n",
    "        tensor = tensor.float()\n",
    "        tensor = tensor / 255.0\n",
    "    if type(mean) == list:\n",
    "        mean = torch.tensor(mean)\n",
    "    if type(std) == list:\n",
    "        std = torch.tensor(std)\n",
    "    tensor = tensor - mean\n",
    "    tensor = tensor / std\n",
    "    return tensor\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
